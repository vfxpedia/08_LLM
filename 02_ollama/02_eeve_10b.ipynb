{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed263bf1-e978-4a15-9002-9ec37caaa4b9",
   "metadata": {},
   "source": [
    "# EEVE-Korean-10.8B 모델 사용 (한국어 특화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcee8125-6091-4516-b673-1e61ff4aef8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model 'EEVE-Korean-10.8B' not found (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m response = \u001b[43mollama\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEEVE-Korean-10.8B\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m안녕하세요. 머신러닝 전문가로 키워주세요!\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ollama\\_client.py:351\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    307\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    308\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    316\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    317\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    318\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    320\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    350\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ollama\\_client.py:189\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    187\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\ollama\\_client.py:133\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    135\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: model 'EEVE-Korean-10.8B' not found (status code: 404)"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='EEVE-Korean-10.8B',\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요. 머신러닝 전문가로 키워주세요!\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91cc918a-4db4-42ff-9979-184f87390a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='EEVE-Korean-10.8B', created_at='2025-10-31T08:24:05.136649261Z', done=True, done_reason='stop', total_duration=8793555630, load_duration=73597691, prompt_eval_count=58, prompt_eval_duration=30350357, eval_count=511, eval_duration=8451149720, message=Message(role='assistant', content='반가워요! 저는 여러분이 머신러닝에 대한 지식과 기술을 향상시키는 데 도움을 주기 위해 여기 있습니다. 머신러닝은 알고리즘과 통계적 모델을 사용하여 데이터에서 학습하고 패턴을 식별하며 예측을 하는 분야입니다. 기계 학습의 한 분야로, 컴퓨터가 새로운 데이터를 기반으로 자신의 성능을 개선하는 것을 가능하게 합니다.\\n\\n머신러닝에 대해 더 배우면서 다음과 같은 주제를 다뤄보죠:\\n\\n1. 머신러닝 소개: 머신러닝이 무엇인지, 어떻게 작동하는지 그리고 그 주요 구성 요소를 이해합니다.\\n2. 슈퍼바이저 학습 대 비슈퍼바이저 학습: 두 가지 주요 유형의 머신러닝 알고리즘의 차이점과 각각의 장점을 논의합니다.\\n3. 분류 및 회귀: 분류와 회귀가 무엇인지, 그리고 데이터 세트를 분류하고 연속적 값을 예측하는 데 어떻게 사용되는지 알아봅니다.\\n4. 특징 공학: 데이터를 전처리하여 머신러닝 모델이 더 잘 작동하도록 만드는 기술을 이해합니다.\\n5. 알고리즘 및 도구: 의사결정 트리와 회귀분석과 같은 인기 있는 머신러닝 알고리즘뿐만 아니라 Scikit-learn, TensorFlow, PyTorch와 같은 다양한 머신러닝 라이브러리에 대해 배웁니다.\\n6. 모델 평가 및 최적화: 정확도, 정밀도, 재현율과 같은 측정 항목을 사용하여 모델을 평가하는 방법과 성능을 향상시키기 위해 모델을 최적화하는 방법을 알아봅니다.\\n7. 자연어 처리 (NLP): 텍스트 데이터를 분석하고 구조화하는 데 머신러닝의 응용 사례를 탐구합니다.\\n8. 이미지 및 영상 처리: 이미지 및 비디오에서 특징을 추출하고 분류하기 위한 다양한 기법을 살펴봅니다.\\n9. 강화학습: 환경에 대한 경험을 통해 새로운 행동을 학습하는 방법에 대해 알아보고 게임, 로보틱스 등에서의 실제 적용 예를 다룹니다.\\n10. 윤리 및 편향성: 머신러닝 모델의 책임있는 개발과 배치에 관련된 윤리적 고려 사항을 논의하고 편향을 인식하고 완화하기 위한 전략을 탐구합니다.\\n\\n이 주제들에 익숙해지면서 여러분은 다양한 머신러닝 프로젝트에 대한 자신감을 얻고 기술을 더욱 향상시킬 수 있을 것입니다. 궁금한 점이나 추가로 배우고 싶은 주제가 있으시면 알려주세요! 함께 이 흥미로운 분야를 배워나가면서 여러분의 머신러닝 여정을 지원하겠습니다.', thinking=None, images=None, tool_name=None, tool_calls=None))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba833da2-c81a-48b3-b8ea-b668595ed44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'반가워요! 저는 여러분이 머신러닝에 대한 지식과 기술을 향상시키는 데 도움을 주기 위해 여기 있습니다. 머신러닝은 알고리즘과 통계적 모델을 사용하여 데이터에서 학습하고 패턴을 식별하며 예측을 하는 분야입니다. 기계 학습의 한 분야로, 컴퓨터가 새로운 데이터를 기반으로 자신의 성능을 개선하는 것을 가능하게 합니다.\\n\\n머신러닝에 대해 더 배우면서 다음과 같은 주제를 다뤄보죠:\\n\\n1. 머신러닝 소개: 머신러닝이 무엇인지, 어떻게 작동하는지 그리고 그 주요 구성 요소를 이해합니다.\\n2. 슈퍼바이저 학습 대 비슈퍼바이저 학습: 두 가지 주요 유형의 머신러닝 알고리즘의 차이점과 각각의 장점을 논의합니다.\\n3. 분류 및 회귀: 분류와 회귀가 무엇인지, 그리고 데이터 세트를 분류하고 연속적 값을 예측하는 데 어떻게 사용되는지 알아봅니다.\\n4. 특징 공학: 데이터를 전처리하여 머신러닝 모델이 더 잘 작동하도록 만드는 기술을 이해합니다.\\n5. 알고리즘 및 도구: 의사결정 트리와 회귀분석과 같은 인기 있는 머신러닝 알고리즘뿐만 아니라 Scikit-learn, TensorFlow, PyTorch와 같은 다양한 머신러닝 라이브러리에 대해 배웁니다.\\n6. 모델 평가 및 최적화: 정확도, 정밀도, 재현율과 같은 측정 항목을 사용하여 모델을 평가하는 방법과 성능을 향상시키기 위해 모델을 최적화하는 방법을 알아봅니다.\\n7. 자연어 처리 (NLP): 텍스트 데이터를 분석하고 구조화하는 데 머신러닝의 응용 사례를 탐구합니다.\\n8. 이미지 및 영상 처리: 이미지 및 비디오에서 특징을 추출하고 분류하기 위한 다양한 기법을 살펴봅니다.\\n9. 강화학습: 환경에 대한 경험을 통해 새로운 행동을 학습하는 방법에 대해 알아보고 게임, 로보틱스 등에서의 실제 적용 예를 다룹니다.\\n10. 윤리 및 편향성: 머신러닝 모델의 책임있는 개발과 배치에 관련된 윤리적 고려 사항을 논의하고 편향을 인식하고 완화하기 위한 전략을 탐구합니다.\\n\\n이 주제들에 익숙해지면서 여러분은 다양한 머신러닝 프로젝트에 대한 자신감을 얻고 기술을 더욱 향상시킬 수 있을 것입니다. 궁금한 점이나 추가로 배우고 싶은 주제가 있으시면 알려주세요! 함께 이 흥미로운 분야를 배워나가면서 여러분의 머신러닝 여정을 지원하겠습니다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51490602-6290-452a-b6dc-dd13b0947f4f",
   "metadata": {},
   "source": [
    "### 간단한 한국어 채팅 시스템 구현\n",
    "\n",
    "- 사용자 입력 input() 이용\n",
    "- 응답 print()로 출력\n",
    "- 이전 대화의 문맥을 반영하며 채팅 이어갈 것\n",
    "- '종료'입력 시 대화 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55727b7-7120-4bd0-bd99-d0b0ebd0889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_eeve():\n",
    "\n",
    "    chat_history = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"입력: \")\n",
    "\n",
    "        if user_input == \"종료\":\n",
    "            break\n",
    "\n",
    "        chat_history.append({\"role\":\"user\", \"content\":user_input})\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=\"EEVE-Korean-10.8B\",\n",
    "            messages=chat_history\n",
    "        )\n",
    "\n",
    "        print(\"EEVE: \", response['message']['content'])\n",
    "\n",
    "        chat_history.append({\"role\":\"assitant\", \"content\":response['message']['content']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d13efff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
