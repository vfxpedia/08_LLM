{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb12df2",
   "metadata": {},
   "source": [
    "# VAE (Variational AutoEncoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87071ea9",
   "metadata": {},
   "source": [
    "### 1. 데이터 로드 및 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a00123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24015c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:02<00:00, 3.60MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 153kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 1.66MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = datasets.MNIST(root='./dataset/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ea26df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./dataset/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8cd71e",
   "metadata": {},
   "source": [
    "### 2. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5eb89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=200, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.img2hid = nn.Linear(input_dim, hidden_dim)\n",
    "        self.hid2mu = nn.Linear(hidden_dim, z_dim)\n",
    "        self.hid2sigma = nn.Linear(hidden_dim, z_dim)\n",
    "\n",
    "        self.z2hid = nn.Linear(z_dim, hidden_dim)\n",
    "        self.hid2img = nn.Linear(hidden_dim, input_dim)\n",
    "\n",
    "        self.relu = nn.ReLU()    \n",
    "\n",
    "    def encoder(self, x):\n",
    "        x = self.img2hid(x)\n",
    "        x = self.relu(x)\n",
    "        mu = self.hid2mu(x)\n",
    "        sigma = self.hid2sigma(x)\n",
    "        return mu, sigma\n",
    " \n",
    "    def decoder(self, z):\n",
    "        z = self.z2hid(z)\n",
    "        z = self.relu(z)\n",
    "        x = self.hid2img(z)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encoder(x)\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z_reparam = mu + sigma * epsilon\n",
    "        x_reconst = self.decoder(z_reparam)\n",
    "        return x_reconst, mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a68fbec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 설정\n",
    "model = VAE(784, 200, 20).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.BCELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a589b3",
   "metadata": {},
   "source": [
    "### 3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f15420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1875it [00:40, 46.16it/s] \n",
      "1875it [01:16, 24.63it/s]\n",
      "1875it [01:15, 24.98it/s]\n",
      "1875it [01:13, 25.38it/s]\n",
      "1875it [00:12, 146.45it/s]\n",
      "1875it [00:11, 163.41it/s]\n",
      "1875it [00:12, 149.11it/s]\n",
      "1875it [00:29, 64.06it/s] \n",
      "1875it [00:23, 78.56it/s] \n",
      "1875it [00:11, 156.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (x, _) in tqdm(enumerate(train_loader)):\n",
    "        x = x.to(device).view(x.shape[0], 784)\n",
    "\n",
    "        x_reconst, mu, sigma = model(x)\n",
    "\n",
    "        reconst_loss = criterion(x_reconst, x)\n",
    "        kl_div = -torch.sum(1 + torch.log(sigma.pow(2)) - mu.pow(2) - sigma.pow(2))\n",
    "\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c83b4e",
   "metadata": {},
   "source": [
    "### 4. 추론 (이미지 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45dfa3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "model = model.to('cpu')\n",
    "\n",
    "def inference(digit, num_samples=3):\n",
    "    images = []\n",
    "    idx = 0\n",
    "\n",
    "    for x, y in dataset:\n",
    "        if y == digit:\n",
    "            images.append(x)\n",
    "            idx += 1\n",
    "\n",
    "            if idx >= num_samples:\n",
    "                break\n",
    "    \n",
    "    encoding_digit = []\n",
    "    for img in images:\n",
    "        with torch.no_grad():\n",
    "            mu, sigma = model.encoder(img.view(1, 784))\n",
    "        encoding_digit.append((mu, sigma))\n",
    "    \n",
    "    for example in range(num_samples):\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z = mu + sigma * epsilon\n",
    "        out = model.decoder(z)\n",
    "        out = out.view(-1, 1, 28, 28)\n",
    "        save_image(out, f\"digit{digit}_sample_{example}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac1356e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee766a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference(9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
