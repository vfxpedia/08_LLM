{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc426153",
   "metadata": {},
   "source": [
    "# Component: Model I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b1086e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953b14d",
   "metadata": {},
   "source": [
    "### PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b868dd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "자동차를 홍보하기 위한 재미있고, 신선한 광고문구를 작성해 주세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "# from langchain import PromptTemplate\n",
    "\n",
    "template=\"{product}를 홍보하기 위한 재미있고, 신선한 광고문구를 작성해 주세요.\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=['product']\n",
    ")\n",
    "\n",
    "print(prompt.format(product='자동차'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e832e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 계산 문제를 해결하세요.\n",
      "\n",
      "Q: 2 + 2는 무엇인가요?\n",
      "A: 2 + 2 = 4\n",
      "\n",
      "Q: 3 + 4는 무엇인가요?\n",
      "A: 3 + 4 = 7\n",
      "\n",
      "Q: 32 + 78은 무엇인가요?\n",
      "A:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "# from langchain.prompts import FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"question\": \"2 + 2는 무엇인가요?\", \"answer\": \"2 + 2 = 4\"},\n",
    "    {\"question\": \"3 + 4는 무엇인가요?\", \"answer\": \"3 + 4 = 7\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    template=\"Q: {question}\\nA: {answer}\",\n",
    "    input_variables=['question', 'answer']\n",
    ")\n",
    "\n",
    "fewshot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=\"다음 계산 문제를 해결하세요.\",\n",
    "    suffix=\"Q: {question}은 무엇인가요?\\nA:\",\n",
    "    input_variables=['question']\n",
    ")\n",
    "\n",
    "print(fewshot_prompt.format(question='32 + 78'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a25269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 친절한 챗봇입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='질문: {question}'), additional_kwargs={})]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='당신은 친절한 챗봇입니다.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='질문: AI를 배우려면 무엇부터 해야 하나요?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ChatPromptTemplate - System, Human, AI 유형별 메세지 작성\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "# from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "sys_msg = SystemMessagePromptTemplate.from_template('당신은 친절한 챗봇입니다.')\n",
    "hm_msg = HumanMessagePromptTemplate.from_template('질문: {question}')\n",
    "msg = ChatPromptTemplate.from_messages([sys_msg, hm_msg])\n",
    "print(msg)\n",
    "\n",
    "msg.format_messages(question=\"AI를 배우려면 무엇부터 해야 하나요?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21502294",
   "metadata": {},
   "source": [
    "### OutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46b3b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OutputParser 인스턴스 및 PromptTemplate 인스턴스 생성\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt_tpl = PromptTemplate(\n",
    "    template=\"{subject} 5개의 팀을 알려주세요. \\n형식 지정: {format}\",\n",
    "    input_variables=['subject'],    # 사용자 입력 변수\n",
    "    partial_variables={'format': format_instructions}   # 고정 설정 변수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41019ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한국의 프로야구팀 5개의 팀을 알려주세요. \n",
      "형식 지정: Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 생성\n",
    "query = \"한국의 프로야구팀\"\n",
    "prompt = prompt_tpl.format(subject=query)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98df5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open AI API를 사용하기 위한 인스턴스 생성 및 요청 처리\n",
    "model = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    max_tokens=2048\n",
    ")\n",
    "\n",
    "response = model.invoke(prompt) # prompt의 질의를 보냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c611d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "두산 베어스, LG 트윈스, 삼성 라이온즈, 키움 히어로즈, NC 다이노스\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n",
    "print(type(response.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b429ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['두산 베어스', 'LG 트윈스', '삼성 라이온즈', '키움 히어로즈', 'NC 다이노스']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(output_parser.parse(response.content))\n",
    "print(type(output_parser.parse(response.content))) # string -> list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f916e729",
   "metadata": {},
   "source": [
    "### HuggingFace Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "348c98e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='사과를 먹었습니다!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 43, 'total_tokens': 49}, 'model_name': 'MLP-KTLim/llama-3-Korean-Bllossom-8B', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--9ccd7dbe-1469-4f65-a56c-dcc113a6d5bb-0', usage_metadata={'input_tokens': 43, 'output_tokens': 6, 'total_tokens': 49})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "# from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "\n",
    "end_point = HuggingFaceEndpoint(\n",
    "    repo_id='MLP-KTLim/llama-3-Korean-Bllossom-8B',\n",
    "    task='text-generation',\n",
    "    max_new_tokens=1024\n",
    ")\n",
    "\n",
    "hf_model = ChatHuggingFace(\n",
    "    llm=end_point,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "hf_model.invoke('저는 아침으로 사과를 먹었습니다. 저는 아침에 무엇을 먹었을까요?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e983b88b",
   "metadata": {},
   "source": [
    "### ModelLaboratory\n",
    "\n",
    "- 여러 LLM을 동시에 비교할 수 있는 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7387670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mInput:\u001b[0m\n",
      "아침에 사과를 먹는 것의 효과를 알려주세요.\n",
      "\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001E00FD931A0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E0102EBC80> root_client=<openai.OpenAI object at 0x000001E00E4C59A0> root_async_client=<openai.AsyncOpenAI object at 0x000001E00FEB50D0> model_name='gpt-4o-mini' temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********') stream_usage=True max_tokens=2048\n",
      "\u001b[36;1m\u001b[1;3m아침에 사과를 먹는 것은 여러 가지 건강상의 이점을 제공합니다. 다음은 그 효과들입니다:\n",
      "\n",
      "1. **영양소 공급**: 사과는 비타민 C, 식이섬유, 항산화 물질이 풍부하여 면역력을 높이고 건강한 피부를 유지하는 데 도움을 줍니다.\n",
      "\n",
      "2. **소화 개선**: 사과에 포함된 식이섬유는 소화를 촉진하고 장 건강을 개선하는 데 도움을 줍니다. 특히 펙틴이라는 섬유소는 장내 유익한 세균의 성장을 도와줍니다.\n",
      "\n",
      "3. **체중 관리**: 사과는 칼로리가 낮고 수분 함량이 높아 포만감을 주어 체중 관리에 도움이 될 수 있습니다. 아침에 사과를 먹으면 과식을 방지하는 데 도움이 됩니다.\n",
      "\n",
      "4. **혈당 조절**: 사과는 혈당 수치를 안정시키는 데 도움을 줄 수 있는 저당 지수를 가지고 있습니다. 이는 아침에 에너지를 지속적으로 공급하는 데 유리합니다.\n",
      "\n",
      "5. **심혈관 건강**: 사과에 포함된 항산화 물질과 식이섬유는 심혈관 건강을 증진시키고, 나쁜 콜레스테롤 수치를 낮추는 데 도움을 줄 수 있습니다.\n",
      "\n",
      "6. **정신적 집중력 향상**: 아침에 사과를 먹으면 뇌에 필요한 에너지를 공급하여 집중력과 기억력을 향상시키는 데 도움이 될 수 있습니다.\n",
      "\n",
      "이러한 이유로 아침에 사과를 먹는 것은 건강한 식습관의 일환으로 추천됩니다. 다만, 개인의 건강 상태나 식이 요구에 따라 적절한 양을 섭취하는 것이 중요합니다.\u001b[0m\n",
      "\n",
      "llm=HuggingFaceEndpoint(repo_id='MLP-KTLim/llama-3-Korean-Bllossom-8B', max_new_tokens=1024, stop_sequences=[], server_kwargs={}, model_kwargs={}, model='MLP-KTLim/llama-3-Korean-Bllossom-8B', client=<InferenceClient(model='MLP-KTLim/llama-3-Korean-Bllossom-8B', timeout=120)>, async_client=<InferenceClient(model='MLP-KTLim/llama-3-Korean-Bllossom-8B', timeout=120)>, task='text-generation') model_id='MLP-KTLim/llama-3-Korean-Bllossom-8B' model_kwargs={}\n",
      "\u001b[33;1m\u001b[1;3m아침에 사과를 먹는 것은 여러 가지 건강적 이점을 제공할 수 있습니다. 사과는 비타민 A, C, K, 칼륨, 마그네슘, 철분 등의 영양소를 풍부하게 포함하고 있어, 신선한 에너지를 공급하고 다양한 신체 기능을 지원합니다. 아침에 사과를 먹는 몇 가지 효과는 다음과 같습니다:\n",
      "\n",
      "1. **에너지 제공**: 사과는 당류인 포도당을 포함하고 있어, 아침에 먹으면 피로를 줄이고 에너지를 공급합니다. 이는 아침 활동을 원활하게 하며, 하루 동안의 에너지 수준을 유지하는 데 도움이 됩니다.\n",
      "\n",
      "2. **콜레스테롤 수치 향상**: 사과는 고지방 식품을 대체할 수 있는 저지방 식품으로, 콜레스테롤 수치를 낮추는 데 도움이 될 수 있습니다. 이는 심혈관 질환의 위험을 줄이는 데 기여할 수 있습니다.\n",
      "\n",
      "3. **배변 운동 촉진**: 사과는 섬유질이 풍부하여 배변 운동을 촉진합니다. 이는 대변의 이동을 원활하게 하여 변비를 예방하고, 장 내부의 건강을 유지하는 데 도움이 됩니다.\n",
      "\n",
      "4. **항산화 작용**: 사과는 항산화 물질을 포함하고 있어, 세포를 손상시키는 자유 라디칼로부터 보호합니다. 이는 노화와 만성 질환의 위험을 줄이는 데 도움이 됩니다.\n",
      "\n",
      "5. **비타민 C 공급**: 사과는 비타민 C가 풍부하여 면역 체계를 강화하고, 감염과 질병을 예방하는 데 도움이 됩니다.\n",
      "\n",
      "6. **혈당 조절**: 사과는 당분이 풍부하지만, 섬유질도 포함되어 있어 혈당 수치를 조절하는 데 도움이 될 수 있습니다. 이는 당뇨병 관리에 유용합니다.\n",
      "\n",
      "7. **위장 건강 개선**: 사과는 펌프를 자극하여 소화 과정의 효율을 높이고, 위장 점막을 건강하게 유지하는 데 도움이 됩니다.\n",
      "\n",
      "8. **스트레스 감소**: 사과는 트립토판을 포함하고 있어, 신경 전달 물질의 생산을 돕고 스트레스를 줄이는 데 도움이 됩니다.\n",
      "\n",
      "이와 같은 이유로, 아침에 사과를 먹는 것은 건강을 유지하고 유지하는 데 매우 효과적인 방법 중 하나입니다. 하지만, 과도한 사과 섭취는 당뇨병 관리에 부정적인 영향을 미칠 수 있으므로, 균형 잡힌 식단 내에서 소량으로 섭취하는 것이 중요합니다.\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_classic.model_laboratory import ModelLaboratory\n",
    "# from langchain.model_laboratory import ModelLaboratory\n",
    "\n",
    "model_lab = ModelLaboratory.from_llms([model, hf_model])\n",
    "model_lab.compare('아침에 사과를 먹는 것의 효과를 알려주세요.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
