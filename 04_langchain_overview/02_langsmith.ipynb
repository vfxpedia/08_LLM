{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f275c473",
   "metadata": {},
   "source": [
    "# LangSmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a91bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langsmith\n",
      "  Downloading langsmith-0.4.37-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from langchain) (2.12.3)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.44-cp39-cp39-win_amd64.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from langchain) (6.0.3)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from langsmith) (3.11.4)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith)\n",
      "  Downloading zstandard-0.25.0-cp39-cp39-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.4-cp39-cp39-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting openai<3.0.0,>=1.104.2 (from langchain-openai)\n",
      "  Downloading openai-2.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp39-cp39-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.9.0)\n",
      "Collecting jiter<1,>=0.10.0 (from openai<3.0.0,>=1.104.2->langchain-openai)\n",
      "  Downloading jiter-0.11.1-cp39-cp39-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from openai<3.0.0,>=1.104.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith) (1.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.10.23)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\anaconda3\\envs\\vectordb_env\\lib\\site-packages (from tqdm>4->openai<3.0.0,>=1.104.2->langchain-openai) (0.4.6)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 24.4 MB/s  0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Downloading langsmith-0.4.37-py3-none-any.whl (396 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp39-cp39-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 60.3 MB/s  0:00:00\n",
      "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
      "Downloading openai-2.7.1-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 49.8 MB/s  0:00:00\n",
      "Downloading jiter-0.11.1-cp39-cp39-win_amd64.whl (207 kB)\n",
      "Downloading tiktoken-0.12.0-cp39-cp39-win_amd64.whl (881 kB)\n",
      "   ---------------------------------------- 0.0/881.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 881.9/881.9 kB 38.7 MB/s  0:00:00\n",
      "Downloading greenlet-3.2.4-cp39-cp39-win_amd64.whl (298 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading zstandard-0.25.0-cp39-cp39-win_amd64.whl (506 kB)\n",
      "Installing collected packages: zstandard, jsonpointer, jiter, greenlet, async-timeout, tiktoken, SQLAlchemy, requests-toolbelt, jsonpatch, openai, langsmith, langchain-core, langchain-text-splitters, langchain-openai, langchain\n",
      "\n",
      "   -------- -------------------------------  3/15 [greenlet]\n",
      "  Attempting uninstall: async-timeout\n",
      "   -------- -------------------------------  3/15 [greenlet]\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "   -------- -------------------------------  3/15 [greenlet]\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "   -------- -------------------------------  3/15 [greenlet]\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "   -------- -------------------------------  3/15 [greenlet]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ---------------- -----------------------  6/15 [SQLAlchemy]\n",
      "   ------------------ ---------------------  7/15 [requests-toolbelt]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   ------------------------ ---------------  9/15 [openai]\n",
      "   -------------------------- ------------- 10/15 [langsmith]\n",
      "   ----------------------------- ---------- 11/15 [langchain-core]\n",
      "   ----------------------------- ---------- 11/15 [langchain-core]\n",
      "   ----------------------------- ---------- 11/15 [langchain-core]\n",
      "   ----------------------------- ---------- 11/15 [langchain-core]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ------------------------------------- -- 14/15 [langchain]\n",
      "   ---------------------------------------- 15/15 [langchain]\n",
      "\n",
      "Successfully installed SQLAlchemy-2.0.44 async-timeout-4.0.3 greenlet-3.2.4 jiter-0.11.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-core-0.3.79 langchain-openai-0.3.35 langchain-text-splitters-0.3.11 langsmith-0.4.37 openai-2.7.1 requests-toolbelt-1.0.0 tiktoken-0.12.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-openai langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59c217",
   "metadata": {},
   "source": [
    "### 로컬 환경에서 LangSmith 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e04ed16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d078ff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.3\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69cf6b6",
   "metadata": {},
   "source": [
    "##### 구글 Colab langsmith 설정\n",
    "#### - colab secret 에 키 등록\n",
    "\n",
    "```python\n",
    "from google.colab import userdata\n",
    "import os\n",
    "\n",
    "os.environ['LANGSMITH_TRACING'] = userdata.get('LANGSMITH_TRACING')\n",
    "os.environ['LANGSMITH_ENDPOINT'] = userdata.get('LANGSMITH_ENDPOINT')\n",
    "os.environ['LANGSMITH_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n",
    "os.environ['LANGSMITH_PROJECT'] = userdata.get('LANGSMITH_PROJECT')\n",
    "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b35964df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "response = llm.invoke(\"Hello World\")   # client.chat.completions.create() -> 질의를 보내고 답변을 받는 함수와 동일 : invoke 메서드 호출\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b5be391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Did Jensen Huang really enjoy eating Kkanbu Chicken?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 42, 'total_tokens': 53, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a788c5aef0', 'id': 'chatcmpl-CY65eGKW0nRFVvuggJHTKB7jh8tYb', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--c1409610-3e85-48fa-8ab7-be0f4f2e1efe-0', usage_metadata={'input_tokens': 42, 'output_tokens': 11, 'total_tokens': 53, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o')\n",
    "llm.invoke([\n",
    "    SystemMessage(content=\"주어진 한글을 영문으로 번역해주세요.\"),\n",
    "    HumanMessage(content=\"젠슨황은 깐부 치킨을 정말 맛있게 먹었을까?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f3cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
