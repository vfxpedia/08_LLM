{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd981a83",
   "metadata": {},
   "source": [
    "# 프롬프트 엔지니어링 with ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ce13ac",
   "metadata": {},
   "source": [
    "## Prompt 설정\n",
    "\n",
    "\n",
    "1. **`temperature`**\n",
    "    - **작동 방식**:  \n",
    "      확률 분포를 **평탄화하거나 집중**시킵니다.\n",
    "      - 낮은 값 (`0.1` 등): 높은 확률의 토큰만 선택하게 하여 응답이 더 **결정적**(예측 가능)입니다.\n",
    "      - 높은 값 (`1.5` 등): 확률 분포를 평탄화하여 저확률 토큰도 선택할 가능성이 있어 응답이 더 **창의적**이고 다양합니다.\n",
    "    \n",
    "    - **적용 범위**:\n",
    "      - 문장이 단조롭거나 응답이 너무 예상 가능할 때 다양성을 부여.\n",
    "      - 확률 분포를 조정하는 가장 기본적인 매개변수.\n",
    "    \n",
    "    - **비유**:\n",
    "      - 음식을 만들 때 **조미료의 양을 조정**하는 것처럼, 다양성을 직접적으로 조절.\n",
    "\n",
    "2. **`top-p`** (또는 **nucleus sampling**)\n",
    "    - **작동 방식**:  \n",
    "      확률 분포에서 누적 확률이 특정 값(`p`) 이하가 되는 상위 토큰들만 고려합니다.  \n",
    "      - 예: `top-p=0.9`라면, 전체 확률의 **90%를 차지하는 상위 토큰**들만 선택 후보로 유지.\n",
    "      - 확률 분포의 **꼬리 부분**(즉, 낮은 확률 토큰)을 잘라내어 선택 가능성을 제한합니다.\n",
    "    \n",
    "    - **적용 범위**:\n",
    "      - 확률이 높은 후보군에 집중하면서도 너무 단조로운 응답을 방지.\n",
    "      - 매우 드문(낮은 확률) 선택지를 배제.\n",
    "    \n",
    "    - **비유**:\n",
    "      - 음식에서 **상위 재료 90%만 골라서 요리**하는 것처럼, 유의미한 선택만 남김.\n",
    "3. **`최대 길이(Max Length)`**\n",
    "    - 생성되는 토큰 수의 최대 길이를 제한한다.\n",
    "    - 길이를 제한하여 응답 품질과 비용을 제어한다.\n",
    "4. **`중지 시퀀스(Stop Sequences)`**\n",
    "    - 특정 문자열에서 응답 생성을 중단한다.\n",
    "    - 응답의 구조와 길이를 제어할 수 있다.\n",
    "5. **`빈도 패널티(Frequency Penalty)`**\n",
    "    - 특정 단어가 자주 반복되지 않도록 페널티를 적용한다.\n",
    "    - 빈도 패널티가 높을수록 단어가 다시 나타날 가능성이 낮아짐.\n",
    "    - 더 많이 나타나는 토큰에 더 높은 패널티를 부여함으로써 모델의 응답에서 단어의 반복을 줄임\n",
    "6. **`존재 패널티(Presence Penalty)`**\n",
    "    - 특정 단어가 한 번이라도 등장하면 페널티를 적용한다.\n",
    "    - 빈도 패널티와 달리, 반복된 토큰에 대한 패널티를 적용하지만, 모든 반복된 토큰에 대해 패널티가 동일하다.\n",
    "        - 두 번 나타나는 토큰과 열 번 나타나는 토큰이 같은 패널티를 받는다.\n",
    "    - 모델이 응답에서 구절을 너무 자주 반복하는 것을 방지\n",
    "    - 모델에게 다양하거나 창의적인 텍스트를 생성하도록 하고 싶다면 높은 존재 패널티를 사용\n",
    "\n",
    "\n",
    "**temperature vs. top-p**\n",
    "\n",
    "| **특징**           | **temperature**                        | **top-p**                            |\n",
    "|---------------------|----------------------------------------|--------------------------------------|\n",
    "| **작동 방식**       | 확률 분포를 평탄화하거나 집중          | 누적 확률 기준으로 후보 제한         |\n",
    "| **결과 다양성**     | 전체 분포에서 다양성을 조정            | 높은 확률 토큰만 사용해 제어          |\n",
    "| **조정 방식**       | 분포의 \"모양\"을 변경                  | 분포의 \"범위\"를 제한                 |\n",
    "| **활용 사례**       | 모델의 창의성이나 결정성 직접 제어     | 비현실적 선택 방지                   |\n",
    "\n",
    "**`temperature`와 `top-p`는 함께 결합해 사용할 수 있다**:\n",
    "- `temperature=0.7, top-p=0.9`\n",
    "- `temperature`로 창의성을 설정하고, `top-p`로 지나치게 낮은 확률의 토큰을 배제하여 모델이 **실용적이면서도 창의적**인 결과를 생성하게 만들수 있다.\n",
    "  \n",
    "\n",
    "### Chat Completion의 구성\n",
    "\n",
    "**프롬프트 구성요소**\n",
    "\n",
    "- **지시사항 `User Message`**: 수행하고자 하는 구체적인 작업에 대한 지시.\n",
    "- **컨텍스트 `System Instruction`**: 페르소나 등의 배경정보, 외부 정보나 추가 세부사항을 제공하여 모델 응답을 보완.\n",
    "- **입력 데이터**: 응답을 유도하기 위한 데이터나 질문.\n",
    "- **출력 지시자**: 응답의 형식과 유형을 명시.\n",
    "\n",
    "\n",
    "**Role**\n",
    "\n",
    "| Role         | 설명                                                                                     | 사용 시점                                                                                          |\n",
    "|--------------|------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------|\n",
    "| `system`     | 대화의 초기 설정과 규칙을 정의                                                           | 대화가 시작될 때 모델의 성격, 행동, 스타일을 설정하는 메시지에서 사용                               |\n",
    "| `user`       | 사용자가 모델에 요청이나 질문을 전달                                                    | 대화 중에 사용자가 요청하거나 질문할 때 사용                                                      |\n",
    "| `assistant`  | 모델이 사용자에게 응답하거나 제안                                                      | 사용자의 질문에 답변하거나 함수 호출을 제안할 때 사용                                              |\n",
    "| `function`   | 함수 호출을 처리하거나 함수의 반환값을 전달                                             | 모델이 함수 호출을 제안하거나 함수가 반환값을 전달할 때 사용                                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "343658c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from openai) (2.12.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4edcdbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89845062",
   "metadata": {},
   "source": [
    "### Chat Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dddf42",
   "metadata": {},
   "source": [
    "chatbot과 대화형 응답을 할 수 있는 Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aad0e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOPENAI_API_KEY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m response = client.chat.completions.create()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\openai\\_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=\"\",\n",
    "    response_format=,\n",
    "    temperature=1.0,         # 대답 창의성\n",
    "    max_tokens=2048,         # 응답 최대 토큰 수\n",
    "    top_p=1.0,               # 사용할 상위 누적 확률\n",
    "    frequency_penalty=0.0,   # 토큰 사용 빈도수에 대한 불이익\n",
    "    presence_penalty=0.0     # 토큰 재사용에 대한 불이익\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97c8f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
