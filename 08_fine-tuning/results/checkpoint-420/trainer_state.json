{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 420,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.11904761904761904,
      "grad_norm": 183.25057983398438,
      "learning_rate": 4.892857142857143e-05,
      "loss": 6.8674,
      "step": 10
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 193.29551696777344,
      "learning_rate": 4.7738095238095245e-05,
      "loss": 6.5293,
      "step": 20
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 64.09735870361328,
      "learning_rate": 4.6547619047619054e-05,
      "loss": 3.8236,
      "step": 30
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 84.38452911376953,
      "learning_rate": 4.5357142857142856e-05,
      "loss": 2.8657,
      "step": 40
    },
    {
      "epoch": 0.5952380952380952,
      "grad_norm": 34.82808303833008,
      "learning_rate": 4.4166666666666665e-05,
      "loss": 1.8006,
      "step": 50
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 72.9769287109375,
      "learning_rate": 4.297619047619048e-05,
      "loss": 1.4679,
      "step": 60
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 8.594425201416016,
      "learning_rate": 4.178571428571429e-05,
      "loss": 1.0174,
      "step": 70
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 19.060670852661133,
      "learning_rate": 4.05952380952381e-05,
      "loss": 0.9232,
      "step": 80
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.1428381204605103,
      "eval_runtime": 8.002,
      "eval_samples_per_second": 124.969,
      "eval_steps_per_second": 10.497,
      "step": 84
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 37.434974670410156,
      "learning_rate": 3.940476190476191e-05,
      "loss": 0.9955,
      "step": 90
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 23.659656524658203,
      "learning_rate": 3.821428571428572e-05,
      "loss": 1.0729,
      "step": 100
    },
    {
      "epoch": 1.3095238095238095,
      "grad_norm": 18.373882293701172,
      "learning_rate": 3.7023809523809526e-05,
      "loss": 0.87,
      "step": 110
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 20.61456871032715,
      "learning_rate": 3.5833333333333335e-05,
      "loss": 0.8123,
      "step": 120
    },
    {
      "epoch": 1.5476190476190477,
      "grad_norm": 4.243882656097412,
      "learning_rate": 3.4642857142857144e-05,
      "loss": 0.8408,
      "step": 130
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 16.395862579345703,
      "learning_rate": 3.345238095238095e-05,
      "loss": 0.754,
      "step": 140
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 57.050559997558594,
      "learning_rate": 3.226190476190477e-05,
      "loss": 0.9263,
      "step": 150
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 30.230005264282227,
      "learning_rate": 3.107142857142857e-05,
      "loss": 0.7789,
      "step": 160
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.7438625693321228,
      "eval_runtime": 7.6843,
      "eval_samples_per_second": 130.135,
      "eval_steps_per_second": 10.931,
      "step": 168
    },
    {
      "epoch": 2.0238095238095237,
      "grad_norm": 5.811673641204834,
      "learning_rate": 2.9880952380952383e-05,
      "loss": 0.7029,
      "step": 170
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 9.109704971313477,
      "learning_rate": 2.869047619047619e-05,
      "loss": 0.6868,
      "step": 180
    },
    {
      "epoch": 2.261904761904762,
      "grad_norm": 25.467567443847656,
      "learning_rate": 2.7500000000000004e-05,
      "loss": 0.5772,
      "step": 190
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 8.389677047729492,
      "learning_rate": 2.6309523809523813e-05,
      "loss": 0.6129,
      "step": 200
    },
    {
      "epoch": 2.5,
      "grad_norm": 22.307043075561523,
      "learning_rate": 2.511904761904762e-05,
      "loss": 0.5348,
      "step": 210
    },
    {
      "epoch": 2.619047619047619,
      "grad_norm": 11.685218811035156,
      "learning_rate": 2.392857142857143e-05,
      "loss": 0.6195,
      "step": 220
    },
    {
      "epoch": 2.738095238095238,
      "grad_norm": 12.028916358947754,
      "learning_rate": 2.273809523809524e-05,
      "loss": 0.6023,
      "step": 230
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 7.819600582122803,
      "learning_rate": 2.154761904761905e-05,
      "loss": 0.4166,
      "step": 240
    },
    {
      "epoch": 2.9761904761904763,
      "grad_norm": 17.878633499145508,
      "learning_rate": 2.0357142857142858e-05,
      "loss": 0.5422,
      "step": 250
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.5480268597602844,
      "eval_runtime": 7.7457,
      "eval_samples_per_second": 129.104,
      "eval_steps_per_second": 10.845,
      "step": 252
    },
    {
      "epoch": 3.0952380952380953,
      "grad_norm": 6.552607536315918,
      "learning_rate": 1.9166666666666667e-05,
      "loss": 0.4993,
      "step": 260
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 8.620881080627441,
      "learning_rate": 1.7976190476190476e-05,
      "loss": 0.4658,
      "step": 270
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 13.344776153564453,
      "learning_rate": 1.6785714285714285e-05,
      "loss": 0.4454,
      "step": 280
    },
    {
      "epoch": 3.4523809523809526,
      "grad_norm": 7.659722328186035,
      "learning_rate": 1.5595238095238098e-05,
      "loss": 0.4296,
      "step": 290
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 7.630169868469238,
      "learning_rate": 1.4404761904761905e-05,
      "loss": 0.4879,
      "step": 300
    },
    {
      "epoch": 3.6904761904761907,
      "grad_norm": 9.556692123413086,
      "learning_rate": 1.3214285714285716e-05,
      "loss": 0.5563,
      "step": 310
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 10.421804428100586,
      "learning_rate": 1.2023809523809525e-05,
      "loss": 0.3912,
      "step": 320
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 20.049734115600586,
      "learning_rate": 1.0833333333333334e-05,
      "loss": 0.4,
      "step": 330
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.4668320417404175,
      "eval_runtime": 7.6691,
      "eval_samples_per_second": 130.393,
      "eval_steps_per_second": 10.953,
      "step": 336
    },
    {
      "epoch": 4.0476190476190474,
      "grad_norm": 7.792011260986328,
      "learning_rate": 9.642857142857144e-06,
      "loss": 0.3873,
      "step": 340
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 11.317541122436523,
      "learning_rate": 8.452380952380953e-06,
      "loss": 0.4415,
      "step": 350
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 23.168413162231445,
      "learning_rate": 7.261904761904763e-06,
      "loss": 0.4363,
      "step": 360
    },
    {
      "epoch": 4.404761904761905,
      "grad_norm": 24.62823486328125,
      "learning_rate": 6.071428571428572e-06,
      "loss": 0.5187,
      "step": 370
    },
    {
      "epoch": 4.523809523809524,
      "grad_norm": 8.17219352722168,
      "learning_rate": 4.880952380952381e-06,
      "loss": 0.3803,
      "step": 380
    },
    {
      "epoch": 4.642857142857143,
      "grad_norm": 6.220072269439697,
      "learning_rate": 3.690476190476191e-06,
      "loss": 0.3566,
      "step": 390
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 9.493172645568848,
      "learning_rate": 2.5e-06,
      "loss": 0.3987,
      "step": 400
    },
    {
      "epoch": 4.880952380952381,
      "grad_norm": 10.323578834533691,
      "learning_rate": 1.3095238095238096e-06,
      "loss": 0.4265,
      "step": 410
    },
    {
      "epoch": 5.0,
      "grad_norm": 20.6468448638916,
      "learning_rate": 1.1904761904761907e-07,
      "loss": 0.3369,
      "step": 420
    }
  ],
  "logging_steps": 10,
  "max_steps": 420,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1324626739200000.0,
  "train_batch_size": 12,
  "trial_name": null,
  "trial_params": null
}
