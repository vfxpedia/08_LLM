{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70965ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2563ce8a-b4c3-422f-ade7-16298e4a6e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting openai\n",
      "  Downloading openai-2.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting hf_xet\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting hf_transfer\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu128)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m153.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.2.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m193.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Downloading openai-2.7.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m127.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
      "Downloading pydantic-2.12.4-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m167.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m155.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading regex-2025.11.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (803 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.5/803.5 kB\u001b[0m \u001b[31m125.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, safetensors, regex, python-dotenv, pydantic-core, jiter, hf_xet, hf_transfer, annotated-types, pydantic, huggingface-hub, tokenizers, openai, transformers, accelerate\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/16\u001b[0m [accelerate]6\u001b[0m [accelerate]s]ub]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.11.0 annotated-types-0.7.0 hf_transfer-0.1.9 hf_xet-1.2.0 huggingface-hub-0.36.0 jiter-0.12.0 openai-2.7.1 pydantic-2.12.4 pydantic-core-2.41.5 python-dotenv-1.2.1 regex-2025.11.3 safetensors-0.6.2 tokenizers-0.22.1 tqdm-4.67.1 transformers-4.57.1 typing-inspection-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv transformers accelerate openai hf_xet hf_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3449b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef4d68b-c661-431a-9b4e-cd07fdf3c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf3ae55c-7269-45fa-8a92-bc311ae5a07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Explain the theory of relativity in simple terms.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7981a832-561e-441f-a3d1-8282df633be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c362164144417a982f145cdadd6c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8231717297d94de3afb9761d06c3e2a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771258cfad3d4ef4980902c84d305493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030a9f9511434303a6d6e9eafe99bdad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97db74af71f40fd93ca630bd6d43314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c650f43db7394b21bdb591ad88672121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab5f3c65f154c4a91646cc8940c3b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6a042a53524a14b7eb6998cd268de8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf71d8b3d5341df89f6d8027bb3f88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "sllm_model_name = 'meta-llama/Llama-3.2-3B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(sllm_model_name)\n",
    "sllm = AutoModelForCausalLM.from_pretrained(sllm_model_name, device_map='auto') # 사용가능한 gpu 자동할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd68a4b-db37-4cc3-9cee-b0ebd3c8c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors='pt').to(sllm.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedc5ed4-a40c-4278-a2ae-388fa8b0763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = sllm.generate(**inputs, max_length=500)\n",
    "sllm_res = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8282f8d9-886a-4ec5-b109-c6fb7f6ff459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the theory of relativity in simple terms. \n",
      "Is the universe expanding, or is it contracting?\n",
      "The theory of relativity, developed by Albert Einstein, is a fundamental concept in modern physics. It consists of two main parts: special relativity and general relativity.\n",
      "**Special Relativity (1905)**\n",
      "\n",
      "In simple terms, special relativity says that how we measure time and space can be different depending on how fast we're moving and where we are. Here are some key points:\n",
      "\n",
      "1. **The speed of light is always constant**: No matter how fast you're moving, the speed of light remains the same (approximately 186,282 miles per second).\n",
      "2. **Time and space are relative**: Time and space can appear different to observers in different states of motion. This is known as time dilation and length contraction.\n",
      "3. **The laws of physics are the same everywhere**: The laws of physics are the same for all observers, regardless of their relative motion.\n",
      "\n",
      "**General Relativity (1915)**\n",
      "\n",
      "General relativity builds upon special relativity and introduces the concept of gravity as a curvature of spacetime caused by massive objects. Here are some key points:\n",
      "\n",
      "1. **Gravity is not a force**: Gravity is not a force that acts between objects, but rather a result of the curvature of spacetime caused by massive objects.\n",
      "2. **Spacetime is curved**: Massive objects warp the fabric of spacetime, creating gravitational fields.\n",
      "3. **The curvature of spacetime affects time and space**: The curvature of spacetime affects not only the motion of objects but also the passage of time.\n",
      "\n",
      "**Is the universe expanding or contracting?**\n",
      "\n",
      "The short answer is: the universe is expanding.\n",
      "\n",
      "The evidence for the expanding universe comes from several lines of observation:\n",
      "\n",
      "1. **Redshift of light from distant galaxies**: The light emitted by galaxies is shifted towards the red end of the spectrum, indicating that those galaxies are moving away from us.\n",
      "2. **Hubble's law**: The velocity of galaxies is proportional to their distance from us, suggesting that the universe is expanding.\n",
      "3. **Cosmic microwave background radiation**: The CMBR is the residual heat from the Big Bang, and its uniformity and tiny fluctuations suggest that the universe is expanding.\n",
      "\n",
      "However, some theories, such as the cyclic model, propose that the universe may be contracting, but this is still a topic of debate among cosmologists.\n",
      "\n",
      "In summary, the theory of relativity revolutionized\n"
     ]
    }
   ],
   "source": [
    "print(sllm_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6809fa2-4737-45bb-9461-51520ebe5cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "gpt_res = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe37a0f0-80fc-4abb-90fb-6787143f608f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theory of relativity, developed by Albert Einstein, includes two main parts: special relativity and general relativity. Here's a simple explanation of both:\n",
      "\n",
      "### Special Relativity\n",
      "\n",
      "1. **Speed of Light is Constant**: No matter how fast you're moving, the speed of light in a vacuum (about 299,792 kilometers per second or 186,282 miles per second) is always the same. This contrasts with our everyday experiences where speeds can vary.\n",
      "\n",
      "2. **Time Dilation**: If you're moving very fast (close to the speed of light), time appears to pass more slowly for you compared to someone who is at rest. This means if you took a fast trip in a spaceship, you would age less than people who stayed on Earth.\n",
      "\n",
      "3. **Length Contraction**: Objects moving close to the speed of light will appear shorter in the direction of motion to someone watching from a stationary position.\n",
      "\n",
      "4. **Mass-Energy Equivalence**: Expressed by the famous equation \\(E=mc^2\\), this principle states that mass can be converted into energy and vice versa. It shows that a small amount of mass can be transformed into a large amount of energy.\n",
      "\n",
      "### General Relativity\n",
      "\n",
      "1. **Gravity as Curvature of Space-Time**: Instead of thinking of gravity as a force pulling objects together, general relativity describes gravity as the bending of space and time (called \"space-time\") caused by mass. Think of a heavy ball placed on a stretched rubber sheet—a smaller ball placed nearby will roll towards the heavy ball due to the curvature.\n",
      "\n",
      "2. **Effect on Time**: Just like with special relativity, time moves differently depending on the influence of gravity. The stronger the gravitational field (like near a planet or star), the slower time passes compared to a weaker field. This means if you were on a strong gravity planet, time would pass a bit slower for you than for someone far away in space.\n",
      "\n",
      "### Summary\n",
      "\n",
      "In simple terms, relativity tells us that time and space are not absolute; they can change based on how fast you're moving and how strong gravity is. It changes our understanding of the universe, showing that things can behave in ways that seem strange compared to our everyday experiences.\n"
     ]
    }
   ],
   "source": [
    "print(gpt_res.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24944fd4-a458-43ac-90fa-d30b1aac00b4",
   "metadata": {},
   "source": [
    "### sLLM-LLM 속도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8b462c7-ae83-4aa5-a94d-53a881cae870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d753a00014465eb9818af56b5005f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3e925546304176ace2232ce3b209de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8f318ab65b45339935c36e1fa7141c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaadcfc51bd7446fa294586009a856e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c63ef081434418398d9131e52c317b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed3373611f84c9797f8a4dab3057cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db33e3b2ce94dc3a8a868bdc384809c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0360fb96f99468abd75761e194326e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "llm = AutoModelForCausalLM.from_pretrained(llm_model_name, device_map='auto') # 사용가능한 gpu 자동할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "809fd450-30b5-4d73-a715-731252e56bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain the benefits of using LLM. Large Language Models (LLMs) have been gaining popularity in recent years, and for good reason. These powerful AI models have numerous benefits that can be applied in various fields, including education, marketing, and healthcare. Here are some of the benefits of using LLMs:\n",
      "\n",
      "1.  **Improved Language Understanding**: LLMs are trained on vast amounts of text data, which enables them to understand complex language structures, nuances, and context. This allows them to generate human-like responses to a wide range of questions and topics.\n",
      "\n",
      "2.  **Enhanced Content Generation**: LLMs can generate high-quality content, such as articles, blog posts, and social media posts, quickly and efficiently. This can be particularly useful for businesses and organizations that need to produce a large volume of content.\n",
      "\n",
      "3.  **Personalized Recommendations**: LLMs can be used to create personalized recommendations based on user behavior, preferences, and interests. This can be applied in e-commerce, entertainment, and other industries where recommendations are a key part of the user experience.\n",
      "\n",
      "4.  **Automated Customer Service**: LLMs can be used to power automated customer service chatbots that can respond to customer inquiries, provide support, and resolve issues.\n",
      "\n",
      "5.  **Medical Diagnosis and Treatment**: LLMs can be used to analyze medical data, diagnose diseases, and develop personalized treatment plans.\n",
      "\n",
      "6.  **Language Translation**: LLMs can be used to translate text and speech in real-time, enabling communication across languages and cultures.\n",
      "\n",
      "7.  **Sentiment Analysis**: LLMs can be used to analyze text data and determine the sentiment behind it, which can be useful for understanding customer opinions, detecting fraud, and more.\n",
      "\n",
      "8.  **Text Summarization**: LLMs can be used to summarize long pieces of text into concise, easy-to-understand summaries, which can be useful for news articles, research papers, and other types of content.\n",
      "\n",
      "9.  **Question Answering**: LLMs can be used to answer complex questions, providing users with accurate and up-to-date information on a wide range of topics.\n",
      "\n",
      "10. **Creative Writing**: LLMs can be used to generate creative writing, such as poetry, short stories, and novels, which can be useful for writers who need ideas or assistance with their work.\n",
      "시간: 8.35초\n",
      "Explain the benefits of using LLM. The benefits of using Large Language Models (LLMs) are numerous and can be categorized into several areas: 1. **Improved Accuracy**: LLMs can process and analyze vast amounts of data, leading to improved accuracy in natural language processing tasks such as language translation, text summarization, and question-answering. 2. **Enhanced Productivity**: LLMs can automate routine tasks, freeing up human time for more strategic and creative work. 3. **Increased Efficiency**: LLMs can process large amounts of data quickly, reducing the time and effort required for tasks such as data annotation, text classification, and sentiment analysis. 4. **Better Decision-Making**: LLMs can provide insights and recommendations based on large amounts of data, enabling better decision-making in areas such as marketing, customer service, and risk management. 5. **Improved Customer Experience**: LLMs can be used to create personalized and engaging customer experiences through chatbots, virtual assistants, and other conversational interfaces. 6. **Enhanced Security**: LLMs can be used to detect and prevent cyber threats, such as phishing and malware attacks, by analyzing large amounts of data and identifying patterns and anomalies. 7. **Increased Accessibility**: LLMs can be used to create accessible interfaces for people with disabilities, such as language translation and text-to-speech systems. 8. **Improved Research**: LLMs can be used to analyze large amounts of research data, identify patterns and relationships, and provide insights that can inform new research directions. 9. **Enhanced Education**: LLMs can be used to create personalized learning experiences, provide feedback and guidance, and help students with language learning and other subjects. 10. **Increased Innovation**: LLMs can be used to generate new ideas, products, and services by analyzing large amounts of data and identifying patterns and relationships. By leveraging these benefits, organizations can improve their operations, enhance customer experiences, and drive innovation. ## Step 2: Explain the limitations of using LLM. While Large Language Models (LLMs) have many benefits, they also have several limitations: 1. **Data Quality**: LLMs are only as good as the data they are trained on. If the data is biased, incomplete, or inaccurate, the LLM will also be biased, incomplete, or inaccurate. 2. **Lack of Common Sense**:\n",
      "시간: 8.26초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "models = [sllm, llm]\n",
    "prompt = 'Explain the benefits of using LLM.'\n",
    "\n",
    "for model in models:\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "\n",
    "    start_time = time.time()\n",
    "    outputs = model.generate(**inputs, max_length=500)\n",
    "    end_time = time.time()\n",
    "\n",
    "    model_res = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(model_res)\n",
    "    print(f'시간: {end_time - start_time:.2f}초')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cdd1a8-69fe-4834-ae2f-91b6626490f5",
   "metadata": {},
   "source": [
    "### 응답 유지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbc14a8b-c95c-45de-ad69-d971d9d0e210",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = 'I am planning a trip to Japan. What are the best cities to visit?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76cf968a-2384-4073-bfad-c47826bbe23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am planning a trip to Japan. What are the best cities to visit? Must-see attractions and experiences\n",
      "Japan is a country with a rich history, vibrant culture, and breathtaking landscapes. Here are some of the best cities to visit in Japan, along with must-see attractions and experiences:\n",
      "\n",
      "**Top Cities to Visit:**\n",
      "\n",
      "1. **Tokyo**: Japan's capital city is a must-visit, with its neon-lit streets, bustling markets, and world-class restaurants. Visit the famous Shibuya Crossing, Tokyo Tower, and the Meiji Shrine.\n",
      "2. **Kyoto**: This city is known for its stunning temples, gardens, and traditional architecture. Visit the Fushimi Inari Shrine, Kinkaku-ji Temple, and the Arashiyama Bamboo Forest.\n",
      "3. **Osaka**: A food lover's paradise, Osaka is famous for its delicious cuisine, including takoyaki and okonomiyaki. Visit the Osaka Castle and the Universal Studios Japan theme park.\n",
      "4. **Hiroshima**: A city with a somber history, Hiroshima is home to the Hiroshima Peace Memorial Park and Museum. Try the city's famous okonomiyaki and visit the Miyajima Island, known for its beautiful scenery and historic landmarks.\n",
      "5. **Sapporo**: Located on the northern island of Hokkaido, Sapporo is a great destination for outdoor enthusiasts. Visit the Sapporo Snow Festival, enjoy the city's hot springs, and try some delicious seafood.\n",
      "\n",
      "**Must-see Attractions:**\n",
      "\n",
      "1. **Mount Fuji**: Japan's iconic mountain is a must-see, especially during cherry blossom season or in the summer when the mountain is surrounded by a beautiful lake.\n",
      "2. **Miyajima Island**: Located near Hiroshima, this island is famous for its beautiful scenery, historic landmarks, and stunning sunsets.\n",
      "3. **Fushimi Inari Shrine**: A famous Shinto shrine in Kyoto, known for its thousands of vermilion torii gates that form a tunnel up the mountain.\n",
      "4. **Tokyo Skytree**: At 634 meters tall, Tokyo Skytree is the tallest tower in the world, offering breathtaking views of the city.\n",
      "5. **Arashiyama Bamboo Forest**: A serene and picturesque forest in Kyoto, perfect for a peaceful stroll.\n",
      "\n",
      "**Experiences:**\n",
      "\n",
      "1. **Onsen (Hot Springs)**: Japan is famous for its natural hot springs, which are\n"
     ]
    }
   ],
   "source": [
    "inputs1 = tokenizer(prompt1, return_tensors='pt').to(sllm.device)\n",
    "outputs1 = sllm.generate(**inputs1, max_length=500)\n",
    "response1 = tokenizer.decode(outputs1[0], skip_special_tokens=True)\n",
    "\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcdf05f7-ddea-4273-9949-a6544612cd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What local food should I try in those cities??\n",
      "Here are the cities I'm interested in visiting:\n",
      "1. New York City, New York\n",
      "2. Los Angeles, California\n",
      "3. Chicago, Illinois\n",
      "4. San Francisco, California\n",
      "5. Boston, Massachusetts\n",
      "6. Washington, D.C.\n",
      "\n",
      "Here are some local specialties to try in each city:\n",
      "\n",
      "**New York City, New York**\n",
      "\n",
      "* Pizza (specifically, try Lombardi's or Joe's Pizza)\n",
      "* Bagels with cream cheese\n",
      "* New York-style hot dogs\n",
      "* Knish (a fried or baked pastry filled with potatoes, meat, or cheese)\n",
      "* Black and white cookies (a classic NYC dessert)\n",
      "\n",
      "**Los Angeles, California**\n",
      "\n",
      "* Tacos (try Guerrilla Tacos or Carnitas El Momo)\n",
      "* Avocado toast (a popular LA brunch item)\n",
      "* In-N-Out Burger (a West Coast institution)\n",
      "* Sushi (try Sushi Gen or Sugarfish)\n",
      "* Fresh fruit (LA is known for its avocado and citrus fruits)\n",
      "\n",
      "**Chicago, Illinois**\n",
      "\n",
      "* Deep-dish pizza (try Lou Malnati's or Pizzeria Uno)\n",
      "* Hot dogs (try Portillo's or Gene's Sausage Shop)\n",
      "* Italian beef sandwiches (try Mr. Beef or Al's Beef)\n",
      "* Polish sausages (try Portillo's or Gene's Sausage Shop)\n",
      "* Chicago-style hot chocolate (try The Berghoff or Intelligentsia Coffee)\n",
      "\n",
      "**San Francisco, California**\n",
      "\n",
      "* Sourdough bread (try Boudin Bakery or Acme Bread Company)\n",
      "* Dungeness crab (try Fisherman's Grotto or Swan Oyster Depot)\n",
      "* Sushi (try Sushi Zo or Zuni Cafe)\n",
      "* Mission-style burritos (try La Taqueria or El Farolito)\n",
      "* Fresh seafood (try The Slanted Door or Fisherman's Grotto)\n",
      "\n",
      "**Boston, Massachusetts**\n",
      "\n",
      "* Clam chowder (try Neptune Oyster or The Union Oyster House)\n",
      "* Lobster rolls (try Neptune Oyster or Red's Sandwich Shop)\n",
      "* Boston cream pie (try Mike's Pastry or Modern Pastry)\n",
      "* Fresh seafood (try The Union Oyster House or Neptune Oyster)\n",
      "* Fenway franks (try Fenway Park or The Sports Bar)\n",
      "\n",
      "**Washington, D.C.**\n",
      "\n",
      "* Ben's Chili Bowl half-smokes (try Ben's Chili Bowl or Old Ebbitt Grill)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt2 = 'What local food should I try in those cities?'\n",
    "\n",
    "inputs2 = tokenizer(prompt2, return_tensors='pt').to(sllm.device)\n",
    "outputs2 = sllm.generate(**inputs2, max_length=500)\n",
    "response2 = tokenizer.decode(outputs2[0], skip_special_tokens=True)\n",
    "\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebfde15-2762-4b95-8646-140383ac7735",
   "metadata": {},
   "source": [
    "### 다국어 처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "342f1895-b3d6-4e55-948b-019edff1ad81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3241c1b9f8fa464fbe50614ae9df9118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c01f85fc6bf47c58cf912767b8d2daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f430545a864841acabfb2f6ab0411b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745181c9f20345b78607fad8a6fc6281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "multilingual_model = pipeline('text-generation', model='meta-llama/Llama-3.1-8B-Instruct', device_map='auto') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e83565d-b751-4ccd-b3f2-c2c12c4ab4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== English ===\n",
      "Where is my cheese? (A tale of a cheese lover's quest for the perfect fromage)\n",
      "I'm a cheese lover. I love all types of cheese - soft and hard, mild and strong, creamy and crumbly. My friends and family often joke that I have a cheese-themed dream life - waking up every morning to a world of brie, gouda, and feta.\n",
      "But, as much as I adore cheese, I've recently found myself on a quest to find the perfect fromage. And, I'm not talking about just any cheese, I'm talking about the crème de la crème of cheeses - the kind that melts in your mouth, the kind that explodes with flavor, the kind that makes you go weak in the knees.\n",
      "My journey began in the rolling hills of the countryside, where I visited a local dairy farm. The farmer, a kind old man with a bushy white beard, showed me around his farm and introduced me to his prize-winning cheddar. It was a beautiful cheese - golden and crumbly, with a rich, tangy flavor. But, as delicious as it was, it wasn't quite what I was looking for.\n",
      "Next, I traveled to a nearby town, where I visited a specialty cheese shop. The shop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Korean ===\n",
      "내 치즈가 어디 갔지?!\n",
      "내 치즈가 어디 갔지?! (Korean title)\n",
      "Where's My Cheese?! (English title)\n",
      "Genre Comedy, Fantasy\n",
      "Written by Kim Jung-hyeon\n",
      "Directed by Kim Jung-hyeon\n",
      "Starring Park Hae-jin\n",
      "Kim Hye-ok\n",
      "Choi Yoon-young\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Min-jae\n",
      "Kim Min-jae (cameo)\n",
      "Lee Won-geun\n",
      "Kim Sung-oh\n",
      "Jung Hye-sun\n",
      "Kim Min-jae (cameo)\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Jung Hye-sun\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "Kim Sung-oh\n",
      "Kim Sung-kyun\n",
      "\n",
      "== Japanese ===\n",
      "私のチーズはどこに行きましたか？ - My cheese is gone somewhere.\n",
      "私はチーズを食べた - I ate the cheese.\n",
      "私はチーズを売った - I sold the cheese.\n",
      "私はチーズを食べた - I ate the cheese. (再び)\n",
      "私のチーズはどこに行きましたか？ - My cheese is gone somewhere. (再び)\n",
      "私はチーズを売った - I sold the cheese. (再び)\n",
      "私はチーズを食べた - I ate the cheese. (再び)\n",
      "私はチーズを売った - I sold the cheese. (再び)\n",
      "私はチーズを食べた - I ate the cheese. (再び)\n",
      "私はチーズを売った - I sold the cheese. (再び)\n",
      "私はチーズを食べた - I ate the cheese. (再び)\n",
      "私はチーズを売った - I sold the cheese. (再び)\n",
      "私はチーズを食べた - I ate the cheese. (再び)\n",
      "私はチーズを売った - I sold the cheese. (再び)\n",
      "私はチーズを食べた - I ate the cheese. (再び)\n",
      "私はチーズを売った - I sold the cheese. (再び)\n",
      "私はチーズを食べた - I ate the cheese.\n"
     ]
    }
   ],
   "source": [
    "prompts = {\n",
    "    'English': 'Where is my cheese?',\n",
    "    'Korean': '내 치즈가 어디 갔지?',\n",
    "    'Japanese': '私のチーズはどこに行きましたか？'\n",
    "}\n",
    "\n",
    "for lang, prompt in prompts.items():\n",
    "    response = multilingual_model(prompt, max_length=100)\n",
    "    print(f\"\\n== {lang} ===\")\n",
    "    print(response[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
