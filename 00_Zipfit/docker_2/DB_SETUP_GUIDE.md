# RAG ì±—ë´‡ DB ì ‘ê·¼ ê°€ì´ë“œ (Windows íŒ€ì›ìš©)

## ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [ì˜µì…˜ 1: Dockerë¡œ ë¡œì»¬ DB ì‹¤í–‰ (ê¶Œì¥)](#ì˜µì…˜-1-dockerë¡œ-ë¡œì»¬-db-ì‹¤í–‰-ê¶Œì¥)
3. [ì˜µì…˜ 2: ì›ê²© DB ì„œë²„ ì ‘ê·¼](#ì˜µì…˜-2-ì›ê²©-db-ì„œë²„-ì ‘ê·¼)
4. [ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´](#ë°ì´í„°ë² ì´ìŠ¤-ì •ë³´)
5. [ì—°ê²° í…ŒìŠ¤íŠ¸](#ì—°ê²°-í…ŒìŠ¤íŠ¸)
6. [ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™](#ë°±ì—”ë“œí”„ë¡ íŠ¸ì—”ë“œ-ì—°ë™)

---

## ê°œìš”

í˜„ì¬ ë²¡í„°í™”ëœ ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ:
- **ì´ ê³µê³ **: 473ê°œ
- **ë²¡í„°í™” ì™„ë£Œ**: 320ê°œ ê³µê³ 
- **ìƒì„±ëœ ì²­í¬**: 20,352ê°œ
- **DB í¬ê¸°**: 284MB (ë°±ì—… íŒŒì¼ ê¸°ì¤€)

---

## ì˜µì…˜ 1: Dockerë¡œ ë¡œì»¬ DB ì‹¤í–‰ (ê¶Œì¥)

íŒ€ì› ê°ìì˜ ìœˆë„ìš° PCì—ì„œ Dockerë¡œ DBë¥¼ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.

### 1.1 ì‚¬ì „ ì¤€ë¹„

#### Docker Desktop ì„¤ì¹˜
1. [Docker Desktop for Windows](https://www.docker.com/products/docker-desktop/) ë‹¤ìš´ë¡œë“œ
2. ì„¤ì¹˜ í›„ ì¬ë¶€íŒ…
3. Docker Desktop ì‹¤í–‰ í™•ì¸

#### í•„ìš”í•œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ë‹¤ìŒ íŒŒì¼ë“¤ì´ í•„ìš”í•©ë‹ˆë‹¤:
```
3rd-proj/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ schema.sql
â””â”€â”€ backups/
    â””â”€â”€ db_backup_473_local.sql  (284MB)
```

### 1.2 DB ì»¨í…Œì´ë„ˆ ì‹¤í–‰

#### Windows PowerShell ë˜ëŠ” CMDì—ì„œ:

```powershell
# 1. í”„ë¡œì íŠ¸ í´ë”ë¡œ ì´ë™
cd í”„ë¡œì íŠ¸_í´ë”

# 2. Docker Composeë¡œ DB ì‹¤í–‰ (db_dump.sql ì´ë¯¸ í¬í•¨ë˜ì–´ ìˆìŒ)
docker-compose up -d postgres

# 3. ì‹¤í–‰ í™•ì¸
docker ps
```

ì¶œë ¥ ì˜ˆì‹œ:
```
CONTAINER ID   IMAGE          PORTS                    NAMES
abc123def456   postgres:14    0.0.0.0:5432->5432/tcp   rag-chatbot-db
```

### 1.3 ë°ì´í„° ì„í¬íŠ¸

DB ì»¨í…Œì´ë„ˆê°€ ì‹¤í–‰ë˜ë©´ ìë™ìœ¼ë¡œ ë°ì´í„°ê°€ ë¡œë“œë©ë‹ˆë‹¤.

í™•ì¸:
```powershell
docker exec rag-chatbot-db psql -U rag_user -d skn19_3rd_proj -c "SELECT COUNT(*) FROM document_chunks;"
```

ì¶œë ¥:
```
 count
-------
 20352
```

### 1.4 ì—°ê²° ì •ë³´

ë¡œì»¬ PCì—ì„œ DBì— ì ‘ê·¼í•˜ë ¤ë©´:

```
Host: localhost (ë˜ëŠ” 127.0.0.1)
Port: 5432
Database: skn19_3rd_proj
Username: rag_user
Password: skn19
```

### 1.5 Python RAG ì˜ˆì‹œ (ê°„ë‹¨í•œ ì§ˆì˜ì‘ë‹µ)

Dockerë¡œ DBë¥¼ ì‹¤í–‰í•œ í›„ Pythonìœ¼ë¡œ RAG ì§ˆì˜ì‘ë‹µì„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```powershell
pip install psycopg2-binary sentence-transformers openai python-dotenv
```

#### RAG ê²€ìƒ‰ ì˜ˆì‹œ ì½”ë“œ

`simple_rag.py` íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”:

```python
# simple_rag.py
import os
import psycopg2
from psycopg2.extras import RealDictCursor
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()

# DB ì—°ê²° ì„¤ì •
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'skn19_3rd_proj',
    'user': 'rag_user',
    'password': 'skn19'
}

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œ, ì‹œê°„ ì†Œìš”)
print("ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
embedding_model = SentenceTransformer('BAAI/bge-m3')
print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))


def search_similar_chunks(query: str, top_k: int = 5):
    """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œ ì²­í¬ ê²€ìƒ‰"""

    # 1. ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    print(f"\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    query_embedding = embedding_model.encode(query, normalize_embeddings=True).tolist()

    # 2. DBì—ì„œ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor(cursor_factory=RealDictCursor)

    cursor.execute("""
        SELECT
            dc.chunk_text,
            dc.metadata,
            a.id as announcement_id,
            a.title,
            a.category,
            a.region,
            a.notice_type,
            (dc.embedding <=> %s::vector) AS distance,
            (1 - (dc.embedding <=> %s::vector)) AS similarity
        FROM document_chunks dc
        JOIN announcements a ON dc.announcement_id = a.id
        ORDER BY distance
        LIMIT %s
    """, (query_embedding, query_embedding, top_k))

    results = cursor.fetchall()
    cursor.close()
    conn.close()

    return results


def generate_answer(query: str, contexts: list):
    """ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ GPT ë‹µë³€ ìƒì„±"""

    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context_text = "\n\n".join([
        f"[ë¬¸ì„œ {i+1}] {ctx['title']} ({ctx['region']})\n{ctx['chunk_text']}"
        for i, ctx in enumerate(contexts)
    ])

    # GPTì—ê²Œ í”„ë¡¬í”„íŠ¸ ì „ë‹¬
    system_prompt = """ë‹¹ì‹ ì€ LH ê³µê³µì£¼íƒ ì•ˆë‚´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ê³µê³  ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€ í˜•ì‹:
1. ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
2. ê´€ë ¨ ê³µê³  ì •ë³´ (ê³µê³ ëª…, ì§€ì—­)
3. ì¶”ê°€ë¡œ í™•ì¸ì´ í•„ìš”í•œ ì‚¬í•­ì´ ìˆë‹¤ë©´ ì•ˆë‚´

ë¬¸ì„œì— ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”."""

    user_prompt = f"""ì§ˆë¬¸: {query}

ì°¸ê³  ë¬¸ì„œ:
{context_text}

ìœ„ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.3,
        max_tokens=1500
    )

    return response.choices[0].message.content


def rag_query(query: str, top_k: int = 5, show_sources: bool = True):
    """RAG ì „ì²´ íŒŒì´í”„ë¼ì¸"""

    # 1. ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
    results = search_similar_chunks(query, top_k)

    if not results:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2. ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ({len(results)}ê±´):")
    print("=" * 80)
    for i, result in enumerate(results, 1):
        print(f"\n[{i}] {result['title']}")
        print(f"    ì§€ì—­: {result['region']} | ìœ í˜•: {result['notice_type']}")
        print(f"    ìœ ì‚¬ë„: {result['similarity']:.3f}")
        if show_sources:
            print(f"    ë‚´ìš©: {result['chunk_text'][:150]}...")

    # 3. GPTë¡œ ë‹µë³€ ìƒì„±
    print("\n" + "=" * 80)
    print("ğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...\n")

    answer = generate_answer(query, results)

    print("ğŸ’¡ ë‹µë³€:")
    print("=" * 80)
    print(answer)
    print("=" * 80)

    return {
        'query': query,
        'sources': results,
        'answer': answer
    }


# ë©”ì¸ ì‹¤í–‰
if __name__ == "__main__":
    # ì˜ˆì‹œ ì¿¼ë¦¬ë“¤
    queries = [
        "ì„œìš¸ ê°•ë‚¨êµ¬ ì„ëŒ€ì£¼íƒ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
        "ë¬´ì£¼íƒ ì„¸ëŒ€ì£¼ ìê²© ì¡°ê±´ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
        "ì†Œë“ ê¸°ì¤€ì€ ì–´ë–»ê²Œ í™•ì¸í•˜ë‚˜ìš”?"
    ]

    # ëŒ€í™”í˜• ëª¨ë“œ
    print("=" * 80)
    print("LH ê³µê³  RAG ì±—ë´‡ (ì¢…ë£Œ: 'quit' ì…ë ¥)")
    print("=" * 80)

    while True:
        query = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()

        if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
            print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not query:
            continue

        try:
            rag_query(query, top_k=5, show_sources=True)
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
```

#### ì‹¤í–‰ ë°©ë²•

1. `.env` íŒŒì¼ì— OpenAI API í‚¤ ì„¤ì •:
```bash
# .env
OPENAI_API_KEY=your-openai-api-key-here
```

2. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰:
```powershell
python simple_rag.py
```

#### ì‹¤í–‰ ì˜ˆì‹œ

```
ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...
ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!
================================================================================
LH ê³µê³  RAG ì±—ë´‡ (ì¢…ë£Œ: 'quit' ì…ë ¥)
================================================================================

ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ì„œìš¸ ê°•ë‚¨êµ¬ ì„ëŒ€ì£¼íƒ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”

ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: ì„œìš¸ ê°•ë‚¨êµ¬ ì„ëŒ€ì£¼íƒ ì‹ ì²­ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”

ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ (5ê±´):
================================================================================

[1] ì„œìš¸ ì§€ì—­ í–‰ë³µì£¼íƒ ì…ì£¼ì ëª¨ì§‘ê³µê³ 
    ì§€ì—­: ì„œìš¸ | ìœ í˜•: í–‰ë³µì£¼íƒ
    ìœ ì‚¬ë„: 0.754
    ë‚´ìš©: ì‹ ì²­ ë°©ë²• ì¸í„°ë„· ì²­ì•½ LH ì²­ì•½ì„¼í„°(apply.lh.or.kr)ì—ì„œ ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤...

[2] ê°•ë‚¨êµ¬ êµ­ë¯¼ì„ëŒ€ì£¼íƒ ì…ì£¼ì ëª¨ì§‘
    ì§€ì—­: ì„œìš¸ ê°•ë‚¨êµ¬ | ìœ í˜•: êµ­ë¯¼ì„ëŒ€
    ìœ ì‚¬ë„: 0.721
    ë‚´ìš©: ì ‘ìˆ˜ ê¸°ê°„ 2025ë…„ 1ì›” 2ì¼ ~ 1ì›” 10ì¼ ì¸í„°ë„· ì²­ì•½ ì ‘ìˆ˜...

================================================================================
ğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...

ğŸ’¡ ë‹µë³€:
================================================================================
ì„œìš¸ ê°•ë‚¨êµ¬ ì„ëŒ€ì£¼íƒ ì‹ ì²­ ë°©ë²•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

1. **ì‹ ì²­ ë°©ë²•**
   - LH ì²­ì•½ì„¼í„°(apply.lh.or.kr)ì—ì„œ ì¸í„°ë„· ì²­ì•½ ì‹ ì²­
   - ëª¨ë°”ì¼ ì•± 'LH ì²­ì•½ì„¼í„°' ì´ìš© ê°€ëŠ¥

2. **ê´€ë ¨ ê³µê³ **
   - ê°•ë‚¨êµ¬ êµ­ë¯¼ì„ëŒ€ì£¼íƒ ì…ì£¼ì ëª¨ì§‘ (ì„œìš¸ ê°•ë‚¨êµ¬)
   - ì„œìš¸ ì§€ì—­ í–‰ë³µì£¼íƒ ì…ì£¼ì ëª¨ì§‘ê³µê³  (ì„œìš¸)

3. **ì¶”ê°€ í™•ì¸ì‚¬í•­**
   - ì‹ ì²­ ìê²© ì¡°ê±´ í™•ì¸ (ë¬´ì£¼íƒ ì„¸ëŒ€ì£¼, ì†Œë“ ê¸°ì¤€ ë“±)
   - ì ‘ìˆ˜ ê¸°ê°„ í™•ì¸ (ê³µê³ ë³„ë¡œ ìƒì´)
   - í•„ìš” ì„œë¥˜ ì¤€ë¹„ (ì£¼ë¯¼ë“±ë¡ë“±ë³¸, ì†Œë“ì¦ë¹™ì„œë¥˜ ë“±)

ìì„¸í•œ ë‚´ìš©ì€ LH ì²­ì•½ì„¼í„°ë‚˜ í•´ë‹¹ ê³µê³ ë¬¸ì„ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.
================================================================================
```

#### ê°„ë‹¨í•œ ê²€ìƒ‰ë§Œ í•˜ëŠ” ë²„ì „ (OpenAI ì—†ì´)

OpenAI APIê°€ ì—†ì–´ë„ ë²¡í„° ê²€ìƒ‰ë§Œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# simple_search.py
import psycopg2
from psycopg2.extras import RealDictCursor
from sentence_transformers import SentenceTransformer

DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'skn19_3rd_proj',
    'user': 'rag_user',
    'password': 'skn19'
}

print("ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
model = SentenceTransformer('BAAI/bge-m3')
print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

def search(query: str, top_k: int = 5):
    # ì¿¼ë¦¬ ì„ë² ë”©
    query_emb = model.encode(query, normalize_embeddings=True).tolist()

    # DB ê²€ìƒ‰
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor(cursor_factory=RealDictCursor)

    cursor.execute("""
        SELECT
            a.title,
            a.region,
            dc.chunk_text,
            (1 - (dc.embedding <=> %s::vector)) AS similarity
        FROM document_chunks dc
        JOIN announcements a ON dc.announcement_id = a.id
        ORDER BY dc.embedding <=> %s::vector
        LIMIT %s
    """, (query_emb, query_emb, top_k))

    results = cursor.fetchall()
    cursor.close()
    conn.close()

    # ê²°ê³¼ ì¶œë ¥
    print(f"\nğŸ” ê²€ìƒ‰: {query}\n")
    for i, r in enumerate(results, 1):
        print(f"[{i}] {r['title']} ({r['region']})")
        print(f"    ìœ ì‚¬ë„: {r['similarity']:.3f}")
        print(f"    {r['chunk_text'][:200]}...\n")

# í…ŒìŠ¤íŠ¸
search("ë¬´ì£¼íƒ ì„¸ëŒ€ì£¼ ìê²© ì¡°ê±´")
search("ì„œìš¸ ê°•ë‚¨êµ¬ ì„ëŒ€ì£¼íƒ")
```

ì‹¤í–‰:
```powershell
python simple_search.py
```

---

## ì˜µì…˜ 2: ì›ê²© DB ì„œë²„ ì ‘ê·¼

ë§Œì•½ DBë¥¼ í´ë¼ìš°ë“œë‚˜ ì„œë²„ì— ë°°í¬í•œë‹¤ë©´ ì•„ë˜ ë°©ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.

### 2.1 AWS RDS PostgreSQL (ì˜ˆì‹œ)

#### AWS RDS ìƒì„± (ë‹´ë‹¹ìê°€ 1íšŒ ìˆ˜í–‰)

1. AWS Console â†’ RDS â†’ "Create database"
2. ì„¤ì •:
   - Engine: PostgreSQL 14
   - Template: Free tier (ë˜ëŠ” Dev/Test)
   - DB instance identifier: `rag-chatbot-db`
   - Master username: `rag_user`
   - Master password: `skn19` (ë˜ëŠ” ì•ˆì „í•œ ë¹„ë°€ë²ˆí˜¸)
   - Storage: 20GB (ìµœì†Œ)
   - Public access: Yes (íŒ€ì› ì ‘ê·¼ ìœ„í•´)
   - VPC security group: PostgreSQL (5432) í¬íŠ¸ ì—´ê¸°

3. pgvector í™•ì¥ ì„¤ì¹˜:
```sql
CREATE EXTENSION vector;
```

4. ë°ì´í„° ì„í¬íŠ¸:
```powershell
# ë¡œì»¬ì—ì„œ ë°±ì—… íŒŒì¼ ë³µì›
psql -h <RDS-ENDPOINT> -U rag_user -d skn19_3rd_proj < backups/db_backup_473_local.sql
```

#### íŒ€ì› ì—°ê²° ì •ë³´

```
Host: <RDS-ENDPOINT>.rds.amazonaws.com
Port: 5432
Database: skn19_3rd_proj
Username: rag_user
Password: skn19
```

### 2.2 ë‹¤ë¥¸ í´ë¼ìš°ë“œ ì˜µì…˜

- **Google Cloud SQL**: PostgreSQL ì§€ì›, pgvector í™•ì¥ ê°€ëŠ¥
- **Azure Database for PostgreSQL**: pgvector ì§€ì›
- **Supabase**: ë¬´ë£Œ í‹°ì–´, pgvector ê¸°ë³¸ ì§€ì›, ì¶”ì²œ!

---

## ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´

### í…Œì´ë¸” êµ¬ì¡°

#### 1. `announcements` (ê³µê³ )
```sql
-- 320ê°œ ë²¡í„°í™”ëœ ê³µê³  ì •ë³´
id              VARCHAR(50)    -- 'LH_lease_1', 'LH_sale_1', ...
title           TEXT           -- ê³µê³ ëª…
category        VARCHAR(20)    -- 'sale' ë˜ëŠ” 'lease'
region          VARCHAR(100)   -- ì§€ì—­
notice_type     VARCHAR(100)   -- ê³µê³  ìœ í˜•
posted_date     DATE
deadline_date   DATE
is_vectorized   BOOLEAN        -- ë²¡í„°í™” ì™„ë£Œ ì—¬ë¶€
```

#### 2. `announcement_files` (ì²¨ë¶€íŒŒì¼)
```sql
-- ê³µê³ ë³„ PDF íŒŒì¼ ì •ë³´
id                SERIAL
announcement_id   VARCHAR(50)   -- announcements.id FK
file_name         TEXT          -- PDF íŒŒì¼ëª…
is_vectorized     BOOLEAN
```

#### 3. `document_chunks` (RAG í•µì‹¬ í…Œì´ë¸”)
```sql
-- 20,352ê°œ ë²¡í„°í™”ëœ í…ìŠ¤íŠ¸ ì²­í¬
id                BIGSERIAL
announcement_id   VARCHAR(50)   -- announcements.id FK
file_id           INTEGER       -- announcement_files.id FK
chunk_text        TEXT          -- ì²­í¬ í…ìŠ¤íŠ¸
chunk_index       INTEGER       -- íŒŒì¼ ë‚´ ìˆœì„œ
embedding         VECTOR(1024)  -- ì„ë² ë”© ë²¡í„° (BAAI/bge-m3)
metadata          JSONB         -- { file_name, section, has_table, ... }
```

### ì£¼ìš” ì¸ë±ìŠ¤

```sql
-- ë²¡í„° ê²€ìƒ‰ìš© HNSW ì¸ë±ìŠ¤ (ë¹ ë¥¸ ìœ ì‚¬ë„ ê²€ìƒ‰)
CREATE INDEX idx_chunks_embedding ON document_chunks
    USING hnsw (embedding vector_cosine_ops)
    WITH (m = 16, ef_construction = 64);
```

---

## ì—°ê²° í…ŒìŠ¤íŠ¸

### Pythonì—ì„œ ì—°ê²° í…ŒìŠ¤íŠ¸

```python
# test_db_connection.py
import psycopg2
from psycopg2.extras import RealDictCursor

# ì—°ê²° ì •ë³´ (í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •)
DB_CONFIG = {
    'host': 'localhost',  # ë˜ëŠ” RDS endpoint
    'port': 5432,
    'database': 'skn19_3rd_proj',
    'user': 'rag_user',
    'password': 'skn19'
}

try:
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor(cursor_factory=RealDictCursor)

    # 1. ì „ì²´ ê³µê³  ìˆ˜
    cursor.execute("SELECT COUNT(*) as count FROM announcements")
    print(f"ì´ ê³µê³ : {cursor.fetchone()['count']}ê°œ")

    # 2. ë²¡í„°í™”ëœ ê³µê³  ìˆ˜
    cursor.execute("SELECT COUNT(*) as count FROM announcements WHERE is_vectorized = true")
    print(f"ë²¡í„°í™”ëœ ê³µê³ : {cursor.fetchone()['count']}ê°œ")

    # 3. ì²­í¬ ìˆ˜
    cursor.execute("SELECT COUNT(*) as count FROM document_chunks")
    print(f"ì´ ì²­í¬: {cursor.fetchone()['count']:,}ê°œ")

    # 4. ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    cursor.execute("""
        SELECT a.title, dc.chunk_text
        FROM document_chunks dc
        JOIN announcements a ON dc.announcement_id = a.id
        LIMIT 1
    """)
    sample = cursor.fetchone()
    print(f"\nìƒ˜í”Œ ë°ì´í„°:")
    print(f"ê³µê³ : {sample['title'][:50]}...")
    print(f"ì²­í¬: {sample['chunk_text'][:100]}...")

    print("\nâœ… DB ì—°ê²° ì„±ê³µ!")

    cursor.close()
    conn.close()

except Exception as e:
    print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
```

ì‹¤í–‰:
```powershell
python test_db_connection.py
```

### pgAdminìœ¼ë¡œ ì—°ê²° (GUI ë„êµ¬)

1. [pgAdmin ë‹¤ìš´ë¡œë“œ](https://www.pgadmin.org/download/)
2. ì„¤ì¹˜ í›„ ì‹¤í–‰
3. Add New Server:
   - Name: `RAG Chatbot DB`
   - Host: `localhost` (ë˜ëŠ” ì›ê²© ì„œë²„ ì£¼ì†Œ)
   - Port: `5432`
   - Database: `skn19_3rd_proj`
   - Username: `rag_user`
   - Password: `skn19`

---

## ë°±ì—”ë“œ/í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™

### ë°±ì—”ë“œ (FastAPI/Flask ì˜ˆì‹œ)

#### í™˜ê²½ë³€ìˆ˜ ì„¤ì • (`.env`)

```bash
# .env
DB_HOST=localhost
DB_PORT=5432
DB_NAME=skn19_3rd_proj
DB_USER=rag_user
DB_PASSWORD=skn19
OPENAI_API_KEY=your-openai-api-key
```

#### FastAPI ì—°ê²° ì½”ë“œ

```python
# backend/database.py
import os
from typing import List, Dict
import asyncpg
from dotenv import load_dotenv

load_dotenv()

class Database:
    def __init__(self):
        self.pool = None

    async def connect(self):
        """DB ì—°ê²° í’€ ìƒì„±"""
        self.pool = await asyncpg.create_pool(
            host=os.getenv('DB_HOST'),
            port=int(os.getenv('DB_PORT')),
            database=os.getenv('DB_NAME'),
            user=os.getenv('DB_USER'),
            password=os.getenv('DB_PASSWORD'),
            min_size=5,
            max_size=20
        )

    async def search_similar_chunks(self, query_embedding: List[float], top_k: int = 5) -> List[Dict]:
        """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰"""
        async with self.pool.acquire() as conn:
            results = await conn.fetch("""
                SELECT
                    dc.chunk_text,
                    dc.metadata,
                    a.title,
                    a.category,
                    a.region,
                    (dc.embedding <=> $1::vector) AS distance
                FROM document_chunks dc
                JOIN announcements a ON dc.announcement_id = a.id
                ORDER BY distance
                LIMIT $2
            """, query_embedding, top_k)

            return [dict(row) for row in results]

    async def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        await self.pool.close()

# ì‚¬ìš© ì˜ˆì‹œ
db = Database()
await db.connect()
results = await db.search_similar_chunks(query_embedding, top_k=5)
```

#### API ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì‹œ

```python
# backend/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
import numpy as np
from sentence_transformers import SentenceTransformer

app = FastAPI()
db = Database()
model = SentenceTransformer('BAAI/bge-m3')

class SearchRequest(BaseModel):
    query: str
    top_k: int = 5

@app.on_event("startup")
async def startup():
    await db.connect()

@app.on_event("shutdown")
async def shutdown():
    await db.close()

@app.post("/search")
async def search(request: SearchRequest):
    """ë²¡í„° ê²€ìƒ‰ API"""
    try:
        # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = model.encode(request.query, normalize_embeddings=True).tolist()

        # 2. ìœ ì‚¬ ì²­í¬ ê²€ìƒ‰
        results = await db.search_similar_chunks(query_embedding, request.top_k)

        return {
            "query": request.query,
            "results": results
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/announcements")
async def get_announcements(category: str = None, region: str = None):
    """ê³µê³  ëª©ë¡ ì¡°íšŒ"""
    async with db.pool.acquire() as conn:
        query = "SELECT * FROM announcements WHERE 1=1"
        params = []

        if category:
            params.append(category)
            query += f" AND category = ${len(params)}"

        if region:
            params.append(region)
            query += f" AND region LIKE ${len(params)}"

        results = await conn.fetch(query, *params)
        return [dict(row) for row in results]
```

### í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™

#### API í˜¸ì¶œ ì˜ˆì‹œ (React/TypeScript)

```typescript
// frontend/src/api/search.ts
import axios from 'axios';

const API_BASE_URL = 'http://localhost:8000';

export interface SearchRequest {
  query: string;
  top_k?: number;
}

export interface SearchResult {
  chunk_text: string;
  metadata: any;
  title: string;
  category: string;
  region: string;
  distance: number;
}

export const searchAnnouncements = async (query: string, topK: number = 5): Promise<SearchResult[]> => {
  const response = await axios.post<{ results: SearchResult[] }>(
    `${API_BASE_URL}/search`,
    { query, top_k: topK }
  );
  return response.data.results;
};

export const getAnnouncements = async (category?: string, region?: string) => {
  const params = new URLSearchParams();
  if (category) params.append('category', category);
  if (region) params.append('region', region);

  const response = await axios.get(`${API_BASE_URL}/announcements?${params}`);
  return response.data;
};
```

#### ì‚¬ìš© ì˜ˆì‹œ (React ì»´í¬ë„ŒíŠ¸)

```tsx
// frontend/src/components/Search.tsx
import React, { useState } from 'react';
import { searchAnnouncements, SearchResult } from '../api/search';

export const Search: React.FC = () => {
  const [query, setQuery] = useState('');
  const [results, setResults] = useState<SearchResult[]>([]);
  const [loading, setLoading] = useState(false);

  const handleSearch = async () => {
    setLoading(true);
    try {
      const data = await searchAnnouncements(query, 5);
      setResults(data);
    } catch (error) {
      console.error('ê²€ìƒ‰ ì‹¤íŒ¨:', error);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div>
      <input
        type="text"
        value={query}
        onChange={(e) => setQuery(e.target.value)}
        placeholder="ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
      />
      <button onClick={handleSearch} disabled={loading}>
        {loading ? 'ê²€ìƒ‰ ì¤‘...' : 'ê²€ìƒ‰'}
      </button>

      <div>
        {results.map((result, idx) => (
          <div key={idx}>
            <h3>{result.title}</h3>
            <p>{result.chunk_text.substring(0, 200)}...</p>
            <small>
              {result.category} | {result.region} | ìœ ì‚¬ë„: {(1 - result.distance).toFixed(3)}
            </small>
          </div>
        ))}
      </div>
    </div>
  );
};
```

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. Docker ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ

```powershell
# ë¡œê·¸ í™•ì¸
docker logs rag-chatbot-db

# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose down
docker-compose up -d postgres
```

### 2. ì—°ê²° ê±°ë¶€ (Connection refused)

- Docker Desktopì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸
- ë°©í™”ë²½ì—ì„œ 5432 í¬íŠ¸ í—ˆìš© í™•ì¸
- `docker ps`ë¡œ ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸

### 3. pgvector í™•ì¥ ì˜¤ë¥˜

```sql
-- ìˆ˜ë™ìœ¼ë¡œ í™•ì¥ ì„¤ì¹˜
docker exec -it rag-chatbot-db psql -U rag_user -d skn19_3rd_proj
CREATE EXTENSION IF NOT EXISTS vector;
```

### 4. Windowsì—ì„œ íŒŒì¼ ê²½ë¡œ ë¬¸ì œ

PowerShellì—ì„œ ê²½ë¡œëŠ” `\`ë¥¼ ì‚¬ìš©:
```powershell
copy backups\db_backup_473_local.sql db_dump.sql
```

Git Bashì—ì„œëŠ” `/`ë¥¼ ì‚¬ìš©:
```bash
cp backups/db_backup_473_local.sql db_dump.sql
```

---

## ìš”ì•½

### ë¹ ë¥¸ ì‹œì‘ (Windows íŒ€ì›)

1. Docker Desktop ì„¤ì¹˜
2. í”„ë¡œì íŠ¸ í´ë¡ 
3. DB ë°±ì—… íŒŒì¼ ë³µì‚¬:
   ```powershell
   copy backups\db_backup_473_local.sql db_dump.sql
   ```
4. Docker Compose ì‹¤í–‰:
   ```powershell
   docker-compose up -d postgres
   ```
5. ì—°ê²° í…ŒìŠ¤íŠ¸:
   ```python
   python test_db_connection.py
   ```

### DB ì—°ê²° ì •ë³´

```
Host: localhost
Port: 5432
Database: skn19_3rd_proj
Username: rag_user
Password: skn19
```

### ë¬¸ì˜

DB ì ‘ê·¼ ê´€ë ¨ ë¬¸ì œê°€ ìˆìœ¼ë©´ íŒ€ ì±„ë„ì— ê³µìœ í•´ì£¼ì„¸ìš”!
