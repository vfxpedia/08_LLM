# 07. LLM 프롬프팅 설계

## 7.1 개요

이 문서는 ZIPFIT의 LLM 프롬프팅 전략을 정의합니다. 정확한 정보 제공과 할루시네이션 방지를 최우선 목표로 합니다.

---

## 7.2 시스템 프롬프트 설계

### 7.2.1 기본 페르소나

**[논의 필요]**

방향성:
- ZIPFIT은 공공주택 전문 AI 어시스턴트
- 친절하고 전문적인 톤
- 사용자를 존중하며 맞춤형 답변 제공

페르소나 초안:
```
당신은 ZIPFIT의 공공주택 전문 AI 어시스턴트입니다.

역할:
- LH, SH, GH 공공주택 공고 전문가
- 사용자의 주거 고민을 듣고 최적의 공고를 추천
- 복잡한 공고문을 쉽게 설명
- 정확한 정보만 제공 (할루시네이션 절대 금지)

톤:
- 친절하고 공감하는 태도
- 전문적이지만 쉬운 언어 사용
- 격려하고 응원하는 메시지

제약사항:
- 공고문에 없는 내용은 추측하지 않음
- 모르는 내용은 "확인이 필요합니다"라고 답변
- 개인정보 보호 (수집한 정보 외부 유출 금지)
```

**[사용자 논의 사항]**:
1. 페르소나의 이름이 필요한가? (예: "집핏이", "지피")
2. 톤의 정도: 격식체 vs 반말체 vs 혼용
3. 추가해야 할 역할이나 제약사항

---

### 7.2.2 출력 형식

**[논의 필요]**

방향성:
- 구조화된 답변 제공
- 출처 명시 (공고문 이름, 페이지 번호)
- 단계별 설명

출력 형식 초안:
```
답변 구조:
1. 핵심 답변 (1-2문장)
2. 상세 설명 (필요시)
3. 출처 표시 (공고문/페이지)
4. 추가 질문 유도

예시:
[핵심 답변]
네, 신청 가능합니다. 서울 지역 행복주택 3건을 찾았습니다.

[상세 설명]
자격 조건 분석 결과:
- 연령: 만 19~39세 (충족)
- 무주택 요건 (충족)
- 소득: 도시근로자 월평균소득 120% 이하 (충족)

[출처]
(출처: LH 행복주택 입주자모집공고 p.3)

[추가 질문]
현재 모집 중인 공고를 보여드릴까요?
```

**[사용자 논의 사항]**:
1. 답변 길이 제한이 필요한가?
2. 표, 리스트 등 형식 사용 빈도
3. 출처 표시 방식 (링크, 페이지 번호 등)

---

## 7.3 사용자 질문 유형별 전략

### 7.3.1 자격 조건 확인

**질문 예시**:
- "행복주택 신청할 수 있어?"
- "내가 자격이 되나?"
- "소득 기준이 어떻게 돼?"

**프롬프팅 전략**:

**[논의 필요]**

초안:
```
1. 사용자 정보 확인
   - 이미 저장된 정보 활용
   - 부족한 정보는 추가 질문

2. 공고문에서 자격 요건 검색 (RAG)
   - Vector DB에서 관련 섹션 추출
   - 나이, 소득, 거주 요건 등 확인

3. 조건 매칭
   - 각 요건별로 충족/불충족 판단
   - 명확한 근거 제시

4. 결과 제시
   - 충족 여부 명시
   - 불충족 시 대안 제시
```

**[사용자 논의 사항]**:
1. 경계선 케이스 처리 (예: 소득이 딱 기준선)
2. 불충족 시 어떻게 전달할 것인가?
3. 대안 제시 범위

---

### 7.3.2 공고 비교

**질문 예시**:
- "어떤 공고가 나한테 맞아?"
- "A와 B 중 뭐가 나아?"
- "가장 저렴한 공고는?"

**프롬프팅 전략**:

**[논의 필요]**

초안:
```
1. 비교 기준 파악
   - 사용자 우선순위 (비용, 위치, 시기 등)
   - 명시되지 않으면 종합 평가

2. 공고 정보 추출 (RAG)
   - 보증금, 월세, 위치, 면적, 입주 시기 등
   - 표 형식으로 정리

3. 장단점 분석
   - 각 공고의 강점/약점 명시
   - 사용자 조건에 맞는 추천

4. 추천 순위 제시
   - 1순위, 2순위, 3순위
   - 추천 이유 명확히 설명
```

**[사용자 논의 사항]**:
1. 비교 기준의 우선순위 (비용 vs 위치 vs 시기)
2. 몇 개까지 비교 가능한가?
3. 추천 알고리즘 (단순 비교 vs 가중치 적용)

---

### 7.3.3 용어 설명

**질문 예시**:
- "선계약후검증이 뭐야?"
- "묵시적갱신 뜻 알려줘"
- "계약보증금은?"

**프롬프팅 전략**:

**[논의 필요]**

초안:
```
1. Glossary DB에서 용어 검색
   - definition_easy 우선 제공
   - definition_full은 추가 요청 시

2. 예시 제공
   - 실제 상황에서 어떻게 적용되는지

3. 관련 용어 제시
   - 함께 알아두면 좋은 용어 안내

4. 추가 질문 유도
   - "더 자세히 알고 싶으신가요?"
```

**[사용자 논의 사항]**:
1. 용어 설명 상세도 (간단 vs 상세)
2. 예시의 구체성
3. 법적 근거 포함 여부

---

### 7.3.4 신청 방법 안내

**질문 예시**:
- "어떻게 신청해?"
- "필요한 서류는?"
- "접수 기간 언제야?"

**프롬프팅 전략**:

**[논의 필요]**

초안:
```
1. 공고문에서 신청 절차 추출 (RAG)
   - 접수 기간, 방법, 장소
   - 필요 서류 목록
   - 당첨자 발표일, 계약 기간

2. 단계별 정리
   - 1단계, 2단계, 3단계 형식
   - 각 단계별 주의사항

3. 외부 링크 제공
   - LH 청약센터 등 직접 연결
   - 필요시 화면 캡처 안내

4. 알림 설정 제안
   - 접수일, 발표일 알림
```

**[사용자 논의 사항]**:
1. 신청 대행 기능 필요 여부
2. 서류 작성 도움 범위
3. 외부 링크 연결 방식

---

### 7.3.5 기타 질문 처리

**질문 예시**:
- "이게 뭐야?" (모호한 질문)
- "대출 받고 싶어" (광범위한 질문)
- "이사 비용은?" (범위 밖 질문)

**프롬프팅 전략**:

**[논의 필요]**

초안:
```
1. 질문 명확화
   - 모호한 질문은 재질문
   - "어떤 정보가 필요하신가요?"

2. 범위 밖 질문
   - 공손하게 안내
   - "저는 공공주택 공고 정보를 제공합니다"
   - 대안 제시 (관련 사이트 안내 등)

3. 복잡한 질문
   - 단계별로 나누어 답변
   - "먼저 ~부터 확인해볼까요?"

4. 오류 처리
   - "죄송하지만, 해당 정보를 찾지 못했습니다"
   - 다른 방법 제안
```

**[사용자 논의 사항]**:
1. 범위 밖 질문의 경계 (어디까지 답변?)
2. 오류 메시지 톤
3. 대안 제시 방법

---

## 7.4 RAG 프롬프팅

### 7.4.1 문서 참조 방식

**[논의 필요]**

방향성:
- 공고문 PDF에서 정확한 정보 추출
- 관련 섹션만 선택적으로 참조
- 출처 명시 필수

RAG 프롬프트 초안:
```
[System]
당신은 다음 문서를 참조하여 답변합니다:
{retrieved_documents}

문서 참조 규칙:
1. 문서에 명시된 내용만 답변
2. 추측하지 않음
3. 애매한 경우 "문서에서 명확히 확인되지 않습니다"
4. 출처 표시: (출처: 문서명 p.페이지번호)

[User Query]
{user_question}

[Answer]
```

**[사용자 논의 사항]**:
1. 검색할 문서 개수 (top-k)
2. 유사도 임계값 (threshold)
3. 문서가 없을 때 처리 방법

---

### 7.4.2 할루시네이션 방지

**[논의 필요]**

전략:
1. **Grounding**: 문서에 근거한 답변만
2. **Verification**: 답변 전 검증
3. **Uncertainty Expression**: 불확실하면 명시

할루시네이션 방지 프롬프트:
```
중요한 제약사항:
- 문서에 없는 내용을 지어내지 마세요
- 확실하지 않으면 "확인이 필요합니다"라고 답하세요
- 수치 정보는 정확히 참조하세요 (보증금, 금액 등)
- 날짜 정보는 정확히 참조하세요

잘못된 예:
"보통 1000만원 정도입니다" (X)

올바른 예:
"마포구 공덕동 행복주택 보증금은 1,200만원입니다.
(출처: LH_마포공덕_행복주택.pdf p.5)" (O)
```

**[사용자 논의 사항]**:
1. 할루시네이션 감지 방법
2. 검증 프로세스
3. 오류 보고 시스템

---

## 7.5 테스트 시나리오

### 7.5.1 정확성 테스트

**[논의 필요]**

테스트 케이스:
1. 자격 조건 정확도
   - 테스트: "28세, 소득 350만원, 서울 거주, 무주택"
   - 기대: 정확한 자격 판단

2. 금액 정보 정확도
   - 테스트: "마포구 행복주택 보증금 얼마?"
   - 기대: 정확한 금액 + 출처

3. 날짜 정보 정확도
   - 테스트: "접수 기간 언제야?"
   - 기대: 정확한 날짜 + 출처

### 7.5.2 할루시네이션 테스트

**[논의 필요]**

테스트 케이스:
1. 존재하지 않는 공고 질문
   - 테스트: "강북구 행복주택 있어?" (실제 없음)
   - 기대: "해당 공고를 찾을 수 없습니다"

2. 문서에 없는 정보 질문
   - 테스트: "주차 공간은 몇 대?"
   - 기대: "공고문에서 확인되지 않습니다"

3. 모호한 질문
   - 테스트: "이게 좋아?"
   - 기대: 명확화 질문

### 7.5.3 사용성 테스트

**[논의 필요]**

테스트 케이스:
1. 자연스러운 대화
   - 이전 대화 맥락 기억
   - 대명사 처리 ("그거", "이거")

2. 다양한 표현 이해
   - "신청할 수 있어?" = "자격 돼?" = "가능해?"

3. 오타 처리
   - "행뽁주택" → "행복주택"

---

## 7.6 모델 선정

### 7.6.1 모델 후보

**[논의 필요]**

후보 모델:
1. **GPT-4o-mini** (OpenAI)
   - 장점: 가볍고 빠름, 비용 저렴
   - 단점: GPT-4보다 정확도 낮을 수 있음
   - 비용: 토큰당 $0.00015 (input), $0.0006 (output)

2. **GPT-4o** (OpenAI)
   - 장점: 높은 정확도
   - 단점: 비용 높음
   - 비용: 토큰당 $0.005 (input), $0.015 (output)

3. **Claude 3.5 Sonnet** (Anthropic)
   - 장점: 긴 컨텍스트, 정확성
   - 단점: 한국어 성능 확인 필요
   - 비용: 토큰당 $0.003 (input), $0.015 (output)

**추천**: 초기에는 GPT-4o-mini로 시작, 성능 확인 후 조정

### 7.6.2 하이브리드 전략

**[논의 필요]**

전략:
- 간단한 질문: GPT-4o-mini (비용 절감)
- 복잡한 질문: GPT-4o (정확도 우선)
- 용어 설명: 경량 모델 (Glossary DB 직접 참조)

**[사용자 논의 사항]**:
1. 모델 선정 기준
2. 비용 vs 성능 트레이드오프
3. 한국어 성능 평가 방법

---

## 7.7 프롬프트 버전 관리

**[논의 필요]**

방향성:
- 프롬프트를 코드처럼 버전 관리
- A/B 테스트로 성능 비교
- 지속적인 개선

버전 관리 예시:
```
v1.0: 초기 프롬프트
v1.1: 할루시네이션 방지 강화
v1.2: 출처 표시 형식 개선
v2.0: 멀티턴 대화 개선
```

---

## 7.8 다음 단계

**[사용자와 논의 필요]**:

1. 시스템 프롬프트 최종 확정
2. 질문 유형별 전략 상세화
3. RAG 프롬프트 테스트 및 조정
4. 테스트 케이스 작성 및 실행
5. 모델 선정 및 성능 평가
6. 프롬프트 버전 1.0 배포

---

**작성일**: 2025년 11월 21일

**작성자**: 오흥재

**상태**: 초안 (사용자 논의 필요)
